Diamanti test package path : /home/rajat/diamanti-test-pkg
Default log file location : /home/rajat/diamanti-test-pkg/logs/e2e_log2019-07-11_08-17-24.log
    DEBUG: 2019/07/11 08:17:24 Removing leading and trailing spaces from Ipmi IP of all nodes.
    DEBUG: 2019/07/11 08:17:24 Check all nodes are ready to run test(s):
    DEBUG: 2019/07/11 08:17:24 172.16.230.14 is ready to run test
    DEBUG: 2019/07/11 08:17:24 172.16.230.16 is ready to run test
    DEBUG: 2019/07/11 08:17:24 172.16.230.18 is ready to run test
    DEBUG: 2019/07/11 08:17:41 Local dctl release number :[91m 74 [0m
    DEBUG: 2019/07/11 08:17:41 Remote dctl release number on 172.16.230.14 :[91m 76 [0m
    DEBUG: 2019/07/11 08:17:41 [91mDctl release number mismatch !![0m
    DEBUG: 2019/07/11 08:17:42 Testbed type used is to get list of Tcs is: D10
Running Suite: DWS e2e Suite run 1 of 1
=======================================
Random Seed: [1m1562858244[0m - Will randomize all specs
Will run [1m24[0m of [1m325[0m specs

    DEBUG: 2019/07/11 08:17:42 Planning to run tests on following nodes :
    DEBUG: 2019/07/11 08:17:42 172.16.230.14
    DEBUG: 2019/07/11 08:17:42 172.16.230.16
    DEBUG: 2019/07/11 08:17:42 172.16.230.18
    DEBUG: 2019/07/11 08:17:42 Checking existance of loopback device(s) on all cluster nodes
    DEBUG: 2019/07/11 08:17:53 Checking if cluster already exists 
    DEBUG: 2019/07/11 08:17:53 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 08:17:54 Login to cluster
    DEBUG: 2019/07/11 08:17:54 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 08:17:55 Recording timestamp of all services on all nodes
    DEBUG: 2019/07/11 08:18:01 Updating inventory struct
    DEBUG: 2019/07/11 08:18:01 Overwritting e2e parameter : ExpectedBasicVnicUsageCount
    DEBUG: 2019/07/11 08:18:02 Checking if given pods are in Running state
    DEBUG: 2019/07/11 08:18:02 Checking if given pods are in Running state
    DEBUG: 2019/07/11 08:18:04 Checking if given pods are in Running state
    DEBUG: 2019/07/11 08:18:05 Checking if given pods are in Running state
    DEBUG: 2019/07/11 08:18:05 Labeled all nodes with node=node$

    DEBUG: 2019/07/11 08:18:05 rpm not specified, assuming rpm to be tested is already installed on all nodes
    DEBUG: 2019/07/11 08:18:05 Starting tests
    DEBUG: 2019/07/11 08:18:05 Login to cluster
    DEBUG: 2019/07/11 08:18:05 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 08:18:06 Checking basic Vnic usage
    DEBUG: 2019/07/11 08:18:07 Updating inventory struct
    DEBUG: 2019/07/11 08:18:13 Creating storage classes
    DEBUG: 2019/07/11 08:18:34 rpm=diamanti-cx-2.2.0-76.x86_64
diamanti-cx-docker-core-2.2.0-69.x86_64
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mMirroring.DetachTwoPlexesDuringIOAttachDuringIO Daily SM_PlexDetach-1.5[0m [90mdetaching two plexes during IO & attaching them during IO. Verifying resync is successful[0m 
  [1mdetaches two plexes during IO & attaches them during IO. Verifying resync is successful[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1354[0m
[BeforeEach] detaching two plexes during IO & attaching them during IO. Verifying resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1341
    DEBUG: 2019/07/11 08:18:34 START_TEST Mirroring.DetachTwoPlexesDuringIOAttachDuringIO
    DEBUG: 2019/07/11 08:18:34 Login to cluster
    DEBUG: 2019/07/11 08:18:34 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 08:18:35 Checking basic Vnic usage
    DEBUG: 2019/07/11 08:18:35 Updating inventory struct
    DEBUG: 2019/07/11 08:18:41 Creating storage classes
[It] detaches two plexes during IO & attaches them during IO. Verifying resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1354
    DEBUG: 2019/07/11 08:19:03 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2019/07/11 08:19:09 FBM and L1 usage is Zero across all nodes

    DEBUG: 2019/07/11 08:19:09 Assigning label to nodes where the plexes of mirrored volumes should get scheduled
    DEBUG: 2019/07/11 08:19:09 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 08:19:09 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 08:19:09 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 08:19:09 Creating 8 volumes of random sizes
    DEBUG: 2019/07/11 08:19:09 Mirror Count: 3
    DEBUG: 2019/07/11 08:19:18 Attaching all 8 volumes to node bosserv8
    DEBUG: 2019/07/11 08:19:49 Running WRITE fio job on: bosserv8. FIO Command : echo -e '#!/bin/bash\n\nsudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"wxyz\"-12 --verify_interval=4096 --runtime=200 --blocksize=4K --iodepth=32  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 > /tmp/fio_result.txt & > /dev/null 2>&1' > /tmp/fio_run.sh

    DEBUG: 2019/07/11 08:19:52 Number of running fio process: 11

    DEBUG: 2019/07/11 08:20:53 Detaching first non initiator plex from all the volumes
    DEBUG: 2019/07/11 08:21:27 Detaching second non initiator plex from all the volumes
    DEBUG: 2019/07/11 08:21:52 Reattaching first non initiator plex to all the volumes
    DEBUG: 2019/07/11 08:22:07 Reattaching second non initiator plex to all the volumes
    DEBUG: 2019/07/11 08:22:08 Verifying if Resync of plexes has started
    DEBUG: 2019/07/11 08:22:08 Number of volumes : 8
    DEBUG: 2019/07/11 08:22:08 Checking resync progress on volume : test-vol8
    DEBUG: 2019/07/11 08:22:08 Volume name & Plex : test-vol8.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:22:09 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:22:10 Volume: test-vol8. Resync offset: 2

    DEBUG: 2019/07/11 08:22:11 Volume: test-vol8. Resync offset: 2

    DEBUG: 2019/07/11 08:22:16 Volume: test-vol8. Resync offset: 3

    DEBUG: 2019/07/11 08:22:16 Volume name & Plex : test-vol8.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:22:16 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:22:16 Checking resync progress on volume : test-vol3
    DEBUG: 2019/07/11 08:22:16 Volume name & Plex : test-vol3.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:22:17 Volume "test-vol3" has index "2" in embedded.
    DEBUG: 2019/07/11 08:22:18 Volume: test-vol3. Resync offset: 10

    DEBUG: 2019/07/11 08:22:18 Volume: test-vol3. Resync offset: 11

    DEBUG: 2019/07/11 08:22:18 Volume name & Plex : test-vol3.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:22:18 Volume name & Plex : test-vol3.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:22:18 Checking resync progress on volume : test-vol1
    DEBUG: 2019/07/11 08:22:18 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:22:18 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:22:18 Volume name & Plex : test-vol1.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 08:22:20 Volume "test-vol1" has index "0" in embedded.
    DEBUG: 2019/07/11 08:22:20 Volume: test-vol1. Resync offset: 81

    DEBUG: 2019/07/11 08:22:21 Volume: test-vol1. Resync offset: 85

    DEBUG: 2019/07/11 08:22:21 Checking resync progress on volume : test-vol5
    DEBUG: 2019/07/11 08:22:21 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:22:21 Volume name & Plex : test-vol5.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 08:22:22 Volume "test-vol5" has index "4" in embedded.
    DEBUG: 2019/07/11 08:22:22 Volume: test-vol5. Resync offset: 6

    DEBUG: 2019/07/11 08:22:23 Volume: test-vol5. Resync offset: 6

    DEBUG: 2019/07/11 08:22:29 Volume: test-vol5. Resync offset: 7

    DEBUG: 2019/07/11 08:22:29 Volume name & Plex : test-vol5.p2. Plex State : Detached
    DEBUG: 2019/07/11 08:22:29 Checking resync progress on volume : test-vol4
    DEBUG: 2019/07/11 08:22:29 Volume name & Plex : test-vol4.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:22:30 Volume "test-vol4" has index "3" in embedded.
    DEBUG: 2019/07/11 08:22:30 Volume: test-vol4. Resync offset: 10

    DEBUG: 2019/07/11 08:22:31 Volume: test-vol4. Resync offset: 10

    DEBUG: 2019/07/11 08:22:37 Volume: test-vol4. Resync offset: 11

    DEBUG: 2019/07/11 08:22:37 Volume name & Plex : test-vol4.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:22:37 Volume name & Plex : test-vol4.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:22:37 Checking resync progress on volume : test-vol2
    DEBUG: 2019/07/11 08:22:37 Volume name & Plex : test-vol2.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:22:38 Volume "test-vol2" has index "1" in embedded.
    DEBUG: 2019/07/11 08:22:38 Volume: test-vol2. Resync offset: 34

    DEBUG: 2019/07/11 08:22:39 Volume: test-vol2. Resync offset: 34

    DEBUG: 2019/07/11 08:22:45 Volume: test-vol2. Resync offset: 39

    DEBUG: 2019/07/11 08:22:45 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:22:45 Volume name & Plex : test-vol2.p2. Plex State : Detached
    DEBUG: 2019/07/11 08:22:45 Checking resync progress on volume : test-vol6
    DEBUG: 2019/07/11 08:22:45 Volume name & Plex : test-vol6.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:22:46 Volume "test-vol6" has index "5" in embedded.
    DEBUG: 2019/07/11 08:22:46 Volume: test-vol6. Resync offset: 8

    DEBUG: 2019/07/11 08:22:47 Volume: test-vol6. Resync offset: 9

    DEBUG: 2019/07/11 08:22:47 Volume name & Plex : test-vol6.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:22:47 Volume name & Plex : test-vol6.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:22:47 Checking resync progress on volume : test-vol7
    DEBUG: 2019/07/11 08:22:47 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:22:47 Volume name & Plex : test-vol7.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 08:22:48 Volume "test-vol7" has index "6" in embedded.
    DEBUG: 2019/07/11 08:22:49 Volume: test-vol7. Resync offset: 8

    DEBUG: 2019/07/11 08:22:49 Volume: test-vol7. Resync offset: 8

    DEBUG: 2019/07/11 08:22:55 Volume: test-vol7. Resync offset: 8

    DEBUG: 2019/07/11 08:23:01 Volume: test-vol7. Resync offset: 9

    DEBUG: 2019/07/11 08:23:01 Volume name & Plex : test-vol7.p2. Plex State : Detached
    DEBUG: 2019/07/11 08:23:01 Comparing Volume's UUID with nvme id-ns for all volumes
    DEBUG: 2019/07/11 08:23:04 Waiting for fio job to complete on the node
    DEBUG: 2019/07/11 08:23:12 Verifying if Resync of plexes has completed
    DEBUG: 2019/07/11 08:23:12 Number of volumes : 8
    DEBUG: 2019/07/11 08:23:12 Checking resync progress on volume : test-vol8
    DEBUG: 2019/07/11 08:23:12 Volume name & Plex : test-vol8.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:23:13 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:23:14 Volume: test-vol8. Resync offset: 10

    DEBUG: 2019/07/11 08:23:14 Volume: test-vol8. Resync offset: 10

    DEBUG: 2019/07/11 08:23:20 Volume: test-vol8. Resync offset: 12

    DEBUG: 2019/07/11 08:23:20 Volume name & Plex : test-vol8.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:23:20 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:23:20 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:23:50 Volume name & Plex : test-vol8.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:23:51 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:23:52 Volume: test-vol8. Resync offset: 24

    DEBUG: 2019/07/11 08:23:52 Volume: test-vol8. Resync offset: 24

    DEBUG: 2019/07/11 08:23:58 Volume: test-vol8. Resync offset: 26

    DEBUG: 2019/07/11 08:23:58 Volume name & Plex : test-vol8.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:23:58 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:23:58 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:24:28 Volume name & Plex : test-vol8.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:24:29 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:24:29 Volume: test-vol8. Resync offset: 39

    DEBUG: 2019/07/11 08:24:30 Volume: test-vol8. Resync offset: 39

    DEBUG: 2019/07/11 08:24:36 Volume: test-vol8. Resync offset: 41

    DEBUG: 2019/07/11 08:24:36 Volume name & Plex : test-vol8.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:24:36 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:24:36 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:25:06 Volume name & Plex : test-vol8.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:25:07 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:25:07 Volume: test-vol8. Resync offset: 55

    DEBUG: 2019/07/11 08:25:08 Volume: test-vol8. Resync offset: 55

    DEBUG: 2019/07/11 08:25:14 Volume: test-vol8. Resync offset: 58

    DEBUG: 2019/07/11 08:25:14 Volume name & Plex : test-vol8.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:25:14 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:25:14 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:25:44 Volume name & Plex : test-vol8.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:25:45 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:25:45 Volume: test-vol8. Resync offset: 72

    DEBUG: 2019/07/11 08:25:46 Volume: test-vol8. Resync offset: 72

    DEBUG: 2019/07/11 08:25:51 Volume: test-vol8. Resync offset: 75

    DEBUG: 2019/07/11 08:25:51 Volume name & Plex : test-vol8.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:25:51 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:25:51 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:26:22 Volume name & Plex : test-vol8.p0. Plex State : Resyncing
    DEBUG: 2019/07/11 08:26:23 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:26:23 Volume: test-vol8. Resync offset: 88

    DEBUG: 2019/07/11 08:26:24 Volume: test-vol8. Resync offset: 89

    DEBUG: 2019/07/11 08:26:24 Volume name & Plex : test-vol8.p1. Plex State : Detached
    DEBUG: 2019/07/11 08:26:24 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:26:24 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:26:54 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:26:54 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 08:26:55 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:26:56 Volume: test-vol8. Resync offset: 4

    DEBUG: 2019/07/11 08:26:56 Volume: test-vol8. Resync offset: 4

    DEBUG: 2019/07/11 08:27:02 Volume: test-vol8. Resync offset: 7

    DEBUG: 2019/07/11 08:27:02 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:27:02 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:27:32 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:27:32 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 08:27:33 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:27:34 Volume: test-vol8. Resync offset: 23

    DEBUG: 2019/07/11 08:27:34 Volume: test-vol8. Resync offset: 24

    DEBUG: 2019/07/11 08:27:34 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:27:34 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:28:04 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:28:04 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 08:28:05 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:28:06 Volume: test-vol8. Resync offset: 40

    DEBUG: 2019/07/11 08:28:07 Volume: test-vol8. Resync offset: 40

    DEBUG: 2019/07/11 08:28:12 Volume: test-vol8. Resync offset: 43

    DEBUG: 2019/07/11 08:28:12 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:28:12 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:28:42 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:28:42 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 08:28:43 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:28:44 Volume: test-vol8. Resync offset: 61

    DEBUG: 2019/07/11 08:28:45 Volume: test-vol8. Resync offset: 61

    DEBUG: 2019/07/11 08:28:50 Volume: test-vol8. Resync offset: 64

    DEBUG: 2019/07/11 08:28:50 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:28:50 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:29:20 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:29:20 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 08:29:21 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 08:29:22 Volume: test-vol8. Resync offset: 82

    DEBUG: 2019/07/11 08:29:22 Volume: test-vol8. Resync offset: 82

    DEBUG: 2019/07/11 08:29:28 Volume: test-vol8. Resync offset: 86

    DEBUG: 2019/07/11 08:29:28 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:29:28 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 All plexes of volume "test-vol8" are in "InUse" state.
    DEBUG: 2019/07/11 08:29:58 Checking resync progress on volume : test-vol4
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol4.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol4.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 All plexes of volume "test-vol4" are in "InUse" state.
    DEBUG: 2019/07/11 08:29:58 Checking resync progress on volume : test-vol1
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol1.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 All plexes of volume "test-vol1" are in "InUse" state.
    DEBUG: 2019/07/11 08:29:58 Checking resync progress on volume : test-vol2
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol2.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 All plexes of volume "test-vol2" are in "InUse" state.
    DEBUG: 2019/07/11 08:29:58 Checking resync progress on volume : test-vol3
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol3.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 All plexes of volume "test-vol3" are in "InUse" state.
    DEBUG: 2019/07/11 08:29:58 Checking resync progress on volume : test-vol5
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol5.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol5.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 All plexes of volume "test-vol5" are in "InUse" state.
    DEBUG: 2019/07/11 08:29:58 Checking resync progress on volume : test-vol7
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol7.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol7.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 All plexes of volume "test-vol7" are in "InUse" state.
    DEBUG: 2019/07/11 08:29:58 Checking resync progress on volume : test-vol6
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol6.p1. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 Volume name & Plex : test-vol6.p2. Plex State : InUse
    DEBUG: 2019/07/11 08:29:58 All plexes of volume "test-vol6" are in "InUse" state.
    DEBUG: 2019/07/11 08:30:03 Verifying sha512sum across all plexes
    DEBUG: 2019/07/11 08:30:04 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 08:30:05 Changing preferred plex of volume: test-vol2. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 08:30:06 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 08:30:07 Changing preferred plex of volume: test-vol4. Volume load index: 3.New preferred plex: 0
    DEBUG: 2019/07/11 08:30:08 Changing preferred plex of volume: test-vol5. Volume load index: 4.New preferred plex: 0
    DEBUG: 2019/07/11 08:30:10 Changing preferred plex of volume: test-vol6. Volume load index: 5.New preferred plex: 0
    DEBUG: 2019/07/11 08:30:11 Changing preferred plex of volume: test-vol7. Volume load index: 6.New preferred plex: 0
    DEBUG: 2019/07/11 08:30:12 Changing preferred plex of volume: test-vol8. Volume load index: 7.New preferred plex: 0
    DEBUG: 2019/07/11 08:30:12 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2019/07/11 08:30:13 Calculating cksum for volume test-vol2 and plex p0
    DEBUG: 2019/07/11 08:30:13 Calculating cksum for volume test-vol3 and plex p0
    DEBUG: 2019/07/11 08:30:13 Calculating cksum for volume test-vol4 and plex p0
    DEBUG: 2019/07/11 08:30:13 Calculating cksum for volume test-vol5 and plex p0
    DEBUG: 2019/07/11 08:30:13 Calculating cksum for volume test-vol6 and plex p0
    DEBUG: 2019/07/11 08:30:13 Calculating cksum for volume test-vol7 and plex p0
    DEBUG: 2019/07/11 08:30:13 Calculating cksum for volume test-vol8 and plex p0
    DEBUG: 2019/07/11 08:33:57 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 08:33:58 Changing preferred plex of volume: test-vol2. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 08:33:59 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 08:34:00 Changing preferred plex of volume: test-vol4. Volume load index: 3.New preferred plex: 1
    DEBUG: 2019/07/11 08:34:02 Changing preferred plex of volume: test-vol5. Volume load index: 4.New preferred plex: 1
    DEBUG: 2019/07/11 08:34:03 Changing preferred plex of volume: test-vol6. Volume load index: 5.New preferred plex: 1
    DEBUG: 2019/07/11 08:34:04 Changing preferred plex of volume: test-vol7. Volume load index: 6.New preferred plex: 1
    DEBUG: 2019/07/11 08:34:05 Changing preferred plex of volume: test-vol8. Volume load index: 7.New preferred plex: 1
    DEBUG: 2019/07/11 08:34:06 Calculating cksum for volume test-vol1 and plex p1
    DEBUG: 2019/07/11 08:34:06 Calculating cksum for volume test-vol2 and plex p1
    DEBUG: 2019/07/11 08:34:06 Calculating cksum for volume test-vol3 and plex p1
    DEBUG: 2019/07/11 08:34:06 Calculating cksum for volume test-vol4 and plex p1
    DEBUG: 2019/07/11 08:34:06 Calculating cksum for volume test-vol5 and plex p1
    DEBUG: 2019/07/11 08:34:06 Calculating cksum for volume test-vol6 and plex p1
    DEBUG: 2019/07/11 08:34:06 Calculating cksum for volume test-vol7 and plex p1
    DEBUG: 2019/07/11 08:34:06 Calculating cksum for volume test-vol8 and plex p1
    DEBUG: 2019/07/11 08:37:28 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 08:37:29 Changing preferred plex of volume: test-vol2. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 08:37:30 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 2
    DEBUG: 2019/07/11 08:37:31 Changing preferred plex of volume: test-vol4. Volume load index: 3.New preferred plex: 2
    DEBUG: 2019/07/11 08:37:32 Changing preferred plex of volume: test-vol5. Volume load index: 4.New preferred plex: 2
    DEBUG: 2019/07/11 08:37:33 Changing preferred plex of volume: test-vol6. Volume load index: 5.New preferred plex: 2
    DEBUG: 2019/07/11 08:37:34 Changing preferred plex of volume: test-vol7. Volume load index: 6.New preferred plex: 2
    DEBUG: 2019/07/11 08:37:36 Changing preferred plex of volume: test-vol8. Volume load index: 7.New preferred plex: 2
    DEBUG: 2019/07/11 08:37:36 Calculating cksum for volume test-vol1 and plex p2
    DEBUG: 2019/07/11 08:37:36 Calculating cksum for volume test-vol2 and plex p2
    DEBUG: 2019/07/11 08:37:36 Calculating cksum for volume test-vol3 and plex p2
    DEBUG: 2019/07/11 08:37:36 Calculating cksum for volume test-vol4 and plex p2
    DEBUG: 2019/07/11 08:37:36 Calculating cksum for volume test-vol5 and plex p2
    DEBUG: 2019/07/11 08:37:36 Calculating cksum for volume test-vol6 and plex p2
    DEBUG: 2019/07/11 08:37:37 Calculating cksum for volume test-vol7 and plex p2
    DEBUG: 2019/07/11 08:37:37 Calculating cksum for volume test-vol8 and plex p2
    DEBUG: 2019/07/11 08:40:07 Sha512sum matched for all volumes across all plexes
    DEBUG: 2019/07/11 08:40:07 Detach & Delete all volumes
    DEBUG: 2019/07/11 08:41:16 Removing label from the nodes where the plexes of mirrored volumes were scheduled
    DEBUG: 2019/07/11 08:41:16 Removed label : mirror from node : bosserv9
    DEBUG: 2019/07/11 08:41:16 Removed label : mirror from node : bosserv8
    DEBUG: 2019/07/11 08:41:16 Removed label : mirror from node : bosserv7
[AfterEach] detaching two plexes during IO & attaching them during IO. Verifying resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1350
    DEBUG: 2019/07/11 08:41:16 END_TEST Mirroring.DetachTwoPlexesDuringIOAttachDuringIO Time-taken : 1361.474379847

[32mâ€¢ [SLOW TEST:1361.474 seconds][0m
Mirroring.DetachTwoPlexesDuringIOAttachDuringIO Daily SM_PlexDetach-1.5
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1334[0m
  detaching two plexes during IO & attaching them during IO. Verifying resync is successful
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1336[0m
    detaches two plexes during IO & attaches them during IO. Verifying resync is successful
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1354[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.MaxSizeVolumeDataVerificationAcrossReboot Weekly RS_Reboot-1.6[0m [90mVolume reboot test on remote volume of max possible size[0m 
  [1mreboot test on large remote volumes[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3442[0m
[BeforeEach] Volume reboot test on remote volume of max possible size
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3427
    DEBUG: 2019/07/11 08:41:16 START_TEST RemoteStorage.MaxSizeVolumeDataVerificationAcrossReboot
    DEBUG: 2019/07/11 08:41:16 Login to cluster
    DEBUG: 2019/07/11 08:41:16 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 08:41:17 Checking basic Vnic usage
    DEBUG: 2019/07/11 08:41:17 Updating inventory struct
    DEBUG: 2019/07/11 08:41:23 Creating storage classes
[It] reboot test on large remote volumes
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3442
    DEBUG: 2019/07/11 08:41:45 Computing total available storage space on node bosserv7
    DEBUG: 2019/07/11 08:41:45 Available space on the node is less than the maximum size of volume. Hence, creating a volume of size equal to maximum available space on node
Max Volume size allowed : 8796163276800
Available space on node : 3796751089664

    DEBUG: 2019/07/11 08:41:45 Creating remote volume of max size
    DEBUG: 2019/07/11 08:41:46 Attaching the volume test-vol1
    DEBUG: 2019/07/11 08:41:50 Running Write IOs on the remote volume
    DEBUG: 2019/07/11 08:41:50 Running Write IOs on node : bosserv9 
Command : sudo /usr/local/bin/fio --ioengine=libaio --rw=write --iodepth=16 --numjobs=1 --gtod_reduce=1 --group_reporting --time_based --runtime=1000 --blocksize=4K  --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096  --name=job1 --filename=/dev/nvme1n1
    DEBUG: 2019/07/11 08:59:13 Calculating checksum for the volume before reboot
    DEBUG: 2019/07/11 08:59:14 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2019/07/11 11:15:05 Getting cluster quorum nodes
    DEBUG: 2019/07/11 11:15:05 Powering OFF the node bosserv9
    DEBUG: 2019/07/11 11:15:11 Node 172.16.230.18 took 6 seconds to power off
    DEBUG: 2019/07/11 11:15:11 Ensuring that bosserv9 node is unreachable: 
    DEBUG: 2019/07/11 11:15:11 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 11:15:20 Polling to check until node: bosserv9 goes down
    DEBUG: 2019/07/11 11:16:45 Powering ON the node bosserv9
    DEBUG: 2019/07/11 11:16:46 Node 172.16.230.18 took 1 seconds to power on
    DEBUG: 2019/07/11 11:16:46 Checking if node bosserv9 is reachable or not: 
    DEBUG: 2019/07/11 11:16:46 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 11:17:05 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 11:17:22 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 11:17:39 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 11:17:56 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 11:18:00 bosserv9 is pingable from local machine
    DEBUG: 2019/07/11 11:18:00 Checking ssh port is up or not on node: bosserv9
    DEBUG: 2019/07/11 11:18:30 Waiting for the node(s) to come up and rejoin the cluster
    DEBUG: 2019/07/11 11:18:30 Found '3' nodes
    DEBUG: 2019/07/11 11:18:30 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 11:18:30 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 11:19:12 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 11:19:22 After power cycle/reboot, updating timestamp of node : bosserv9
    DEBUG: 2019/07/11 11:19:24 Getting cluster quorum nodes
    DEBUG: 2019/07/11 11:20:24 Updating inventory struct
    DEBUG: 2019/07/11 11:20:25 Calculating checksum for the volume after reboot
    DEBUG: 2019/07/11 11:20:25 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2019/07/11 13:46:38 Comparing checksum for the volume before and after reboot
    DEBUG: 2019/07/11 13:46:38 Detach & Delete all volumes
[AfterEach] Volume reboot test on remote volume of max possible size
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3437
    DEBUG: 2019/07/11 13:50:18 END_TEST RemoteStorage.MaxSizeVolumeDataVerificationAcrossReboot Time-taken : 18542.433030738

[32mâ€¢ [SLOW TEST:18542.433 seconds][0m
RemoteStorage.MaxSizeVolumeDataVerificationAcrossReboot Weekly RS_Reboot-1.6
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3419[0m
  Volume reboot test on remote volume of max possible size
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3422[0m
    reboot test on large remote volumes
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3442[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mMirroring.OnlinePlexAdd  Daily SM_PlexAdd-1.5[0m [90mCreate several simple volumes and add [online] plexes to these volumes.[0m 
  [1mCreate simple volumes, do IOs, add plexes, validate data on each plex of each volume.[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1910[0m
[BeforeEach] Create several simple volumes and add [online] plexes to these volumes.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1896
    DEBUG: 2019/07/11 13:50:18 START_TEST Mirroring.OnlinePlexAdd
    DEBUG: 2019/07/11 13:50:18 Login to cluster
    DEBUG: 2019/07/11 13:50:18 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 13:50:19 Checking basic Vnic usage
    DEBUG: 2019/07/11 13:50:19 Updating inventory struct
    DEBUG: 2019/07/11 13:50:26 Creating storage classes
[It] Create simple volumes, do IOs, add plexes, validate data on each plex of each volume.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1910
    DEBUG: 2019/07/11 13:50:48 Creating 8 volumes. Mirror Count: 1:
    DEBUG: 2019/07/11 13:50:48 Mirror Count: 1
    DEBUG: 2019/07/11 13:50:52 Attaching volumes: 
    DEBUG: 2019/07/11 13:51:22 Running write fio job on all volumes: 
    DEBUG: 2019/07/11 13:51:23 Running Write IOs on node : bosserv8 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=120 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 13:51:23 Running Write IOs on node : bosserv9 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=120 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 13:51:23 Running Write IOs on node : bosserv7 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=120 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 13:53:24 Adding new plex to each simple volumes. Expected PlexCount 2: 
    DEBUG: 2019/07/11 13:53:25 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:53:25 Volume name & Plex : test-vol1.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 13:53:26 Volume "test-vol1" has index "0" in embedded.
    DEBUG: 2019/07/11 13:53:27 Volume: test-vol1. Resync offset: 63

    DEBUG: 2019/07/11 13:53:27 Volume: test-vol1. Resync offset: 76

    DEBUG: 2019/07/11 13:53:27 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 13:53:57 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:53:57 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:53:57 All plexes of volume "test-vol1" are in "InUse" state.
    DEBUG: 2019/07/11 13:53:57 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:53:57 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:53:57 All plexes of volume "test-vol2" are in "InUse" state.
    DEBUG: 2019/07/11 13:53:57 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:53:57 Volume name & Plex : test-vol3.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 13:53:58 Volume "test-vol3" has index "0" in embedded.
    DEBUG: 2019/07/11 13:53:59 Volume: test-vol3. Resync offset: 90

    DEBUG: 2019/07/11 13:54:00 Volume: test-vol3. Resync offset: 91

    DEBUG: 2019/07/11 13:54:00 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 13:54:30 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:54:30 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:54:30 All plexes of volume "test-vol3" are in "InUse" state.
    DEBUG: 2019/07/11 13:54:30 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:54:30 Volume name & Plex : test-vol4.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:54:30 All plexes of volume "test-vol4" are in "InUse" state.
    DEBUG: 2019/07/11 13:54:30 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:54:30 Volume name & Plex : test-vol5.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 13:54:31 Volume "test-vol5" has index "1" in embedded.
    DEBUG: 2019/07/11 13:54:31 Volume: test-vol5. Resync offset: 99

    DEBUG: 2019/07/11 13:54:32 Volume: test-vol5. Resync offset: 
    DEBUG: 2019/07/11 13:54:33 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 13:55:03 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:55:03 Volume name & Plex : test-vol5.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:55:03 All plexes of volume "test-vol5" are in "InUse" state.
    DEBUG: 2019/07/11 13:55:03 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:55:03 Volume name & Plex : test-vol6.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:55:03 All plexes of volume "test-vol6" are in "InUse" state.
    DEBUG: 2019/07/11 13:55:03 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:55:03 Volume name & Plex : test-vol7.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:55:03 All plexes of volume "test-vol7" are in "InUse" state.
    DEBUG: 2019/07/11 13:55:03 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:55:03 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 13:55:04 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 13:55:04 Volume: test-vol8. Resync offset: 96

    DEBUG: 2019/07/11 13:55:05 Volume: test-vol8. Resync offset: 97

    DEBUG: 2019/07/11 13:55:05 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 13:55:35 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:55:35 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:55:35 All plexes of volume "test-vol8" are in "InUse" state.
    DEBUG: 2019/07/11 13:55:35 Running read fio job on all volumes: 
    DEBUG: 2019/07/11 13:55:36 Changing preferred plex of volume: test-vol3. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 13:55:36 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 13:55:36 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 13:55:37 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 13:55:37 Changing preferred plex of volume: test-vol4. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 13:55:37 Changing preferred plex of volume: test-vol5. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 13:55:38 Running Verify IOs on node : bosserv8 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 13:55:38 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 13:55:38 Changing preferred plex of volume: test-vol7. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 13:55:39 Running Verify IOs on node : bosserv9 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 13:55:39 Running Verify IOs on node : bosserv7 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 13:56:37 Changing preferred plex of volume: test-vol3. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 13:56:38 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 13:56:38 Running Verify IOs on node : bosserv8 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 13:56:42 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 13:56:43 Changing preferred plex of volume: test-vol4. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 13:56:44 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 13:56:45 Running Verify IOs on node : bosserv9 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 13:56:45 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 13:56:46 Changing preferred plex of volume: test-vol5. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 13:56:47 Changing preferred plex of volume: test-vol7. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 13:56:48 Running Verify IOs on node : bosserv7 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 13:58:32 Adding new plex to each simple volumes. Expected PlexCount 3: 
    DEBUG: 2019/07/11 13:58:33 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:58:33 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:58:33 Volume name & Plex : test-vol1.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 13:58:34 Volume "test-vol1" has index "0" in embedded.
    DEBUG: 2019/07/11 13:58:34 Volume: test-vol1. Resync offset: 60

    DEBUG: 2019/07/11 13:58:35 Volume: test-vol1. Resync offset: 73

    DEBUG: 2019/07/11 13:58:35 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 13:59:05 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:59:05 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:59:05 Volume name & Plex : test-vol1.p2. Plex State : InUse
    DEBUG: 2019/07/11 13:59:05 All plexes of volume "test-vol1" are in "InUse" state.
    DEBUG: 2019/07/11 13:59:05 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:59:05 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:59:05 Volume name & Plex : test-vol2.p2. Plex State : InUse
    DEBUG: 2019/07/11 13:59:05 All plexes of volume "test-vol2" are in "InUse" state.
    DEBUG: 2019/07/11 13:59:05 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:59:05 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:59:05 Volume name & Plex : test-vol3.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 13:59:06 Volume "test-vol3" has index "0" in embedded.
    DEBUG: 2019/07/11 13:59:07 Volume: test-vol3. Resync offset: 93

    DEBUG: 2019/07/11 13:59:08 Volume: test-vol3. Resync offset: 94

    DEBUG: 2019/07/11 13:59:08 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 13:59:38 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:59:38 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:59:38 Volume name & Plex : test-vol3.p2. Plex State : InUse
    DEBUG: 2019/07/11 13:59:38 All plexes of volume "test-vol3" are in "InUse" state.
    DEBUG: 2019/07/11 13:59:38 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:59:38 Volume name & Plex : test-vol4.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:59:38 Volume name & Plex : test-vol4.p2. Plex State : InUse
    DEBUG: 2019/07/11 13:59:38 All plexes of volume "test-vol4" are in "InUse" state.
    DEBUG: 2019/07/11 13:59:38 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 13:59:38 Volume name & Plex : test-vol5.p1. Plex State : InUse
    DEBUG: 2019/07/11 13:59:38 Volume name & Plex : test-vol5.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 13:59:39 Volume "test-vol5" has index "1" in embedded.
    DEBUG: 2019/07/11 13:59:39 Volume: test-vol5. Resync offset: 99

    DEBUG: 2019/07/11 13:59:40 Volume: test-vol5. Resync offset: 
    DEBUG: 2019/07/11 13:59:40 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 14:00:10 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:00:10 Volume name & Plex : test-vol5.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:00:10 Volume name & Plex : test-vol5.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:00:10 All plexes of volume "test-vol5" are in "InUse" state.
    DEBUG: 2019/07/11 14:00:11 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:00:11 Volume name & Plex : test-vol6.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:00:11 Volume name & Plex : test-vol6.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:00:11 All plexes of volume "test-vol6" are in "InUse" state.
    DEBUG: 2019/07/11 14:00:11 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:00:11 Volume name & Plex : test-vol7.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:00:11 Volume name & Plex : test-vol7.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:00:11 All plexes of volume "test-vol7" are in "InUse" state.
    DEBUG: 2019/07/11 14:00:11 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:00:11 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:00:11 Volume name & Plex : test-vol8.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 14:00:12 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 14:00:12 Volume: test-vol8. Resync offset: 95

    DEBUG: 2019/07/11 14:00:13 Volume: test-vol8. Resync offset: 95

    DEBUG: 2019/07/11 14:00:19 Volume: test-vol8. Resync offset: 
    DEBUG: 2019/07/11 14:00:19 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 14:00:49 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:00:49 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:00:49 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:00:49 All plexes of volume "test-vol8" are in "InUse" state.
    DEBUG: 2019/07/11 14:00:49 Running read fio job on all volumes: 
    DEBUG: 2019/07/11 14:00:50 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 14:00:50 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 14:00:50 Changing preferred plex of volume: test-vol3. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 14:00:51 Changing preferred plex of volume: test-vol4. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 14:00:51 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 14:00:51 Changing preferred plex of volume: test-vol5. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 14:00:52 Running Verify IOs on node : bosserv8 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 14:00:52 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 14:00:52 Changing preferred plex of volume: test-vol7. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 14:00:53 Running Verify IOs on node : bosserv9 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 14:00:53 Running Verify IOs on node : bosserv7 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 14:01:51 Changing preferred plex of volume: test-vol3. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 14:01:53 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 14:01:53 Running Verify IOs on node : bosserv8 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 14:01:56 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 14:01:57 Changing preferred plex of volume: test-vol4. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 14:01:58 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 14:01:58 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 14:01:59 Running Verify IOs on node : bosserv9 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 14:01:59 Changing preferred plex of volume: test-vol5. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 14:02:00 Changing preferred plex of volume: test-vol7. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 14:02:01 Running Verify IOs on node : bosserv7 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 14:03:31 Changing preferred plex of volume: test-vol3. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 14:03:32 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 14:03:33 Running Verify IOs on node : bosserv8 and plex p2
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 14:03:39 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 14:03:40 Changing preferred plex of volume: test-vol4. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 14:03:41 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 2
    DEBUG: 2019/07/11 14:03:42 Running Verify IOs on node : bosserv9 and plex p2
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 14:03:43 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 14:03:44 Changing preferred plex of volume: test-vol5. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 14:03:45 Changing preferred plex of volume: test-vol7. Volume load index: 2.New preferred plex: 2
    DEBUG: 2019/07/11 14:03:46 Running Verify IOs on node : bosserv7 and plex p2
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 14:05:27 Detach & delete all volumes: 
[AfterEach] Create several simple volumes and add [online] plexes to these volumes.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1906
    DEBUG: 2019/07/11 14:06:20 END_TEST Mirroring.OnlinePlexAdd Time-taken : 961.549815567

[32mâ€¢ [SLOW TEST:961.550 seconds][0m
Mirroring.OnlinePlexAdd  Daily SM_PlexAdd-1.5
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1889[0m
  Create several simple volumes and add [online] plexes to these volumes.
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1890[0m
    Create simple volumes, do IOs, add plexes, validate data on each plex of each volume.
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1910[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mMirroring.ResyncSingleTargetReboot Weekly SM_Reboot-2.5[0m [90mreboot a target node while IO is in progress and verify resync is successful[0m 
  [1mreboot a target node while IO is in progress and verify resync is successful[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:487[0m
[BeforeEach] reboot a target node while IO is in progress and verify resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:473
    DEBUG: 2019/07/11 14:06:20 START_TEST Mirroring.ResyncSingleTargetReboot
    DEBUG: 2019/07/11 14:06:20 Login to cluster
    DEBUG: 2019/07/11 14:06:20 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 14:06:21 Checking basic Vnic usage
    DEBUG: 2019/07/11 14:06:21 Updating inventory struct
    DEBUG: 2019/07/11 14:06:27 Creating storage classes
[It] reboot a target node while IO is in progress and verify resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:487
    DEBUG: 2019/07/11 14:06:49 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2019/07/11 14:06:56 FBM and L1 usage is Zero across all nodes

    DEBUG: 2019/07/11 14:06:56 Assigning label to nodes where the plexes of mirrored volumes should get scheduled
    DEBUG: 2019/07/11 14:06:56 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 14:06:56 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 14:06:56 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 14:06:56 Creating 8 volumes of random sizes
    DEBUG: 2019/07/11 14:06:56 Mirror Count: 3
    DEBUG: 2019/07/11 14:07:05 Attaching all 8 volumes to node bosserv9
    DEBUG: 2019/07/11 14:07:35 Initiator node : bosserv9
    DEBUG: 2019/07/11 14:07:35 Nodes to reboot : bosserv7
    DEBUG: 2019/07/11 14:07:39 Running WRITE fio job on: bosserv9. FIO Command : echo -e '#!/bin/bash\n\nsudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"akpz\"-12 --verify_interval=4096 --runtime=400 --blocksize=4K --iodepth=32  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 > /tmp/fio_result.txt & > /dev/null 2>&1' > /tmp/fio_run.sh

    DEBUG: 2019/07/11 14:07:42 Number of running fio process: 11

    DEBUG: 2019/07/11 14:11:02 Getting cluster quorum nodes
    DEBUG: 2019/07/11 14:11:02 Powering OFF the node bosserv7
    DEBUG: 2019/07/11 14:11:09 Node 172.16.230.14 took 6 seconds to power off
    DEBUG: 2019/07/11 14:11:09 Ensuring that bosserv7 node is unreachable: 
    DEBUG: 2019/07/11 14:11:09 Executing ping command: ping  -c 5 -W 5 bosserv7
    DEBUG: 2019/07/11 14:11:18 Polling to check until node: bosserv7 goes down
    DEBUG: 2019/07/11 14:11:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:39 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:40 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:41 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:44 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:45 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:45 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:45 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:45 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:11:50 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:13:06 Powering ON the node bosserv7
    DEBUG: 2019/07/11 14:13:07 Node 172.16.230.14 took 1 seconds to power on
    DEBUG: 2019/07/11 14:13:07 Checking if node bosserv7 is reachable or not: 
    DEBUG: 2019/07/11 14:13:07 Executing ping command: ping  -c 5 -W 5 bosserv7
    DEBUG: 2019/07/11 14:13:24 Executing ping command: ping  -c 5 -W 5 bosserv7
    DEBUG: 2019/07/11 14:13:41 Executing ping command: ping  -c 5 -W 5 bosserv7
    DEBUG: 2019/07/11 14:13:58 Executing ping command: ping  -c 5 -W 5 bosserv7
    DEBUG: 2019/07/11 14:14:15 Executing ping command: ping  -c 5 -W 5 bosserv7
    DEBUG: 2019/07/11 14:14:19 bosserv7 is pingable from local machine
    DEBUG: 2019/07/11 14:14:19 Checking ssh port is up or not on node: bosserv7
    DEBUG: 2019/07/11 14:14:49 Waiting for the node(s) to come up and rejoin the cluster
    DEBUG: 2019/07/11 14:14:49 Found '3' nodes
    DEBUG: 2019/07/11 14:14:49 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 14:15:25 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 14:15:25 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 14:15:35 After power cycle/reboot, updating timestamp of node : bosserv7
    DEBUG: 2019/07/11 14:15:37 Getting cluster quorum nodes
    DEBUG: 2019/07/11 14:16:37 Updating inventory struct
    DEBUG: 2019/07/11 14:16:38 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2019/07/11 14:16:50 Nodes are up, waiting for armada to start
.
    DEBUG: 2019/07/11 14:18:00 Waiting for the nodes to go into Ready state
    DEBUG: 2019/07/11 14:18:00 Found '3' nodes
    DEBUG: 2019/07/11 14:18:00 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 14:18:00 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 14:18:00 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 14:18:00 Waiting for volumes to come into Attached state after rebooting cluster nodes.
    DEBUG: 2019/07/11 14:18:03 Comparing Volume's UUID with nvme id-ns for all volumes
    DEBUG: 2019/07/11 14:18:07 Comparing the device path & uuid on initiator before and after target reboot
    DEBUG: 2019/07/11 14:18:07 Number of volumes : 8
    DEBUG: 2019/07/11 14:18:07 Checking resync progress on volume : test-vol8
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 All plexes of volume "test-vol8" are in "InUse" state.
    DEBUG: 2019/07/11 14:18:07 Checking resync progress on volume : test-vol4
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol4.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol4.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 All plexes of volume "test-vol4" are in "InUse" state.
    DEBUG: 2019/07/11 14:18:07 Checking resync progress on volume : test-vol1
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol1.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 All plexes of volume "test-vol1" are in "InUse" state.
    DEBUG: 2019/07/11 14:18:07 Checking resync progress on volume : test-vol2
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol2.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 All plexes of volume "test-vol2" are in "InUse" state.
    DEBUG: 2019/07/11 14:18:07 Checking resync progress on volume : test-vol3
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 Volume name & Plex : test-vol3.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:18:07 All plexes of volume "test-vol3" are in "InUse" state.
    DEBUG: 2019/07/11 14:18:07 Checking resync progress on volume : test-vol7
    DEBUG: 2019/07/11 14:18:08 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:18:08 Volume name & Plex : test-vol7.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:18:08 Volume name & Plex : test-vol7.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:18:08 All plexes of volume "test-vol7" are in "InUse" state.
    DEBUG: 2019/07/11 14:18:08 Checking resync progress on volume : test-vol5
    DEBUG: 2019/07/11 14:18:08 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:18:08 Volume name & Plex : test-vol5.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:18:08 Volume name & Plex : test-vol5.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:18:08 All plexes of volume "test-vol5" are in "InUse" state.
    DEBUG: 2019/07/11 14:18:08 Checking resync progress on volume : test-vol6
    DEBUG: 2019/07/11 14:18:08 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:18:08 Volume name & Plex : test-vol6.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:18:08 Volume name & Plex : test-vol6.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:18:08 All plexes of volume "test-vol6" are in "InUse" state.
    DEBUG: 2019/07/11 14:18:13 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 14:18:14 Changing preferred plex of volume: test-vol2. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 14:18:15 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 14:18:16 Changing preferred plex of volume: test-vol4. Volume load index: 3.New preferred plex: 0
    DEBUG: 2019/07/11 14:18:17 Changing preferred plex of volume: test-vol5. Volume load index: 4.New preferred plex: 0
    DEBUG: 2019/07/11 14:18:18 Changing preferred plex of volume: test-vol6. Volume load index: 5.New preferred plex: 0
    DEBUG: 2019/07/11 14:18:19 Changing preferred plex of volume: test-vol7. Volume load index: 6.New preferred plex: 0
    DEBUG: 2019/07/11 14:18:21 Changing preferred plex of volume: test-vol8. Volume load index: 7.New preferred plex: 0
    DEBUG: 2019/07/11 14:18:21 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2019/07/11 14:18:21 Calculating cksum for volume test-vol2 and plex p0
    DEBUG: 2019/07/11 14:18:21 Calculating cksum for volume test-vol3 and plex p0
    DEBUG: 2019/07/11 14:18:21 Calculating cksum for volume test-vol4 and plex p0
    DEBUG: 2019/07/11 14:18:21 Calculating cksum for volume test-vol5 and plex p0
    DEBUG: 2019/07/11 14:18:21 Calculating cksum for volume test-vol6 and plex p0
    DEBUG: 2019/07/11 14:18:22 Calculating cksum for volume test-vol7 and plex p0
    DEBUG: 2019/07/11 14:18:22 Calculating cksum for volume test-vol8 and plex p0
    DEBUG: 2019/07/11 14:19:50 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 14:19:51 Changing preferred plex of volume: test-vol2. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 14:19:52 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 14:19:53 Changing preferred plex of volume: test-vol4. Volume load index: 3.New preferred plex: 1
    DEBUG: 2019/07/11 14:19:55 Changing preferred plex of volume: test-vol5. Volume load index: 4.New preferred plex: 1
    DEBUG: 2019/07/11 14:19:56 Changing preferred plex of volume: test-vol6. Volume load index: 5.New preferred plex: 1
    DEBUG: 2019/07/11 14:19:57 Changing preferred plex of volume: test-vol7. Volume load index: 6.New preferred plex: 1
    DEBUG: 2019/07/11 14:19:58 Changing preferred plex of volume: test-vol8. Volume load index: 7.New preferred plex: 1
    DEBUG: 2019/07/11 14:19:59 Calculating cksum for volume test-vol1 and plex p1
    DEBUG: 2019/07/11 14:19:59 Calculating cksum for volume test-vol2 and plex p1
    DEBUG: 2019/07/11 14:19:59 Calculating cksum for volume test-vol3 and plex p1
    DEBUG: 2019/07/11 14:19:59 Calculating cksum for volume test-vol4 and plex p1
    DEBUG: 2019/07/11 14:19:59 Calculating cksum for volume test-vol5 and plex p1
    DEBUG: 2019/07/11 14:19:59 Calculating cksum for volume test-vol6 and plex p1
    DEBUG: 2019/07/11 14:19:59 Calculating cksum for volume test-vol7 and plex p1
    DEBUG: 2019/07/11 14:19:59 Calculating cksum for volume test-vol8 and plex p1
    DEBUG: 2019/07/11 14:22:27 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 14:22:28 Changing preferred plex of volume: test-vol2. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 14:22:29 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 2
    DEBUG: 2019/07/11 14:22:30 Changing preferred plex of volume: test-vol4. Volume load index: 3.New preferred plex: 2
    DEBUG: 2019/07/11 14:22:31 Changing preferred plex of volume: test-vol5. Volume load index: 4.New preferred plex: 2
    DEBUG: 2019/07/11 14:22:32 Changing preferred plex of volume: test-vol6. Volume load index: 5.New preferred plex: 2
    DEBUG: 2019/07/11 14:22:33 Changing preferred plex of volume: test-vol7. Volume load index: 6.New preferred plex: 2
    DEBUG: 2019/07/11 14:22:34 Changing preferred plex of volume: test-vol8. Volume load index: 7.New preferred plex: 2
    DEBUG: 2019/07/11 14:22:35 Calculating cksum for volume test-vol1 and plex p2
    DEBUG: 2019/07/11 14:22:35 Calculating cksum for volume test-vol2 and plex p2
    DEBUG: 2019/07/11 14:22:35 Calculating cksum for volume test-vol3 and plex p2
    DEBUG: 2019/07/11 14:22:35 Calculating cksum for volume test-vol4 and plex p2
    DEBUG: 2019/07/11 14:22:35 Calculating cksum for volume test-vol5 and plex p2
    DEBUG: 2019/07/11 14:22:35 Calculating cksum for volume test-vol6 and plex p2
    DEBUG: 2019/07/11 14:22:35 Calculating cksum for volume test-vol7 and plex p2
    DEBUG: 2019/07/11 14:22:35 Calculating cksum for volume test-vol8 and plex p2
    DEBUG: 2019/07/11 14:25:05 Successfully completed Verification on all the plexes
    DEBUG: 2019/07/11 14:25:05 Detach & Delete all volumes
    DEBUG: 2019/07/11 14:26:45 Removing label from the nodes where the plexes of mirrored volumes were scheduled
    DEBUG: 2019/07/11 14:26:46 Removed label : mirror from node : bosserv7
    DEBUG: 2019/07/11 14:26:46 Removed label : mirror from node : bosserv9
    DEBUG: 2019/07/11 14:26:46 Removed label : mirror from node : bosserv8
[AfterEach] reboot a target node while IO is in progress and verify resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:482
    DEBUG: 2019/07/11 14:26:46 END_TEST Mirroring.ResyncSingleTargetReboot Time-taken : 1225.772187072

[32mâ€¢ [SLOW TEST:1225.772 seconds][0m
Mirroring.ResyncSingleTargetReboot Weekly SM_Reboot-2.5
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:466[0m
  reboot a target node while IO is in progress and verify resync is successful
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:468[0m
    reboot a target node while IO is in progress and verify resync is successful
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:487[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.MultiSVDataVerification Weekly RS_Verify-1.6[0m [90mcreate remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs[0m 
  [1mcreates remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3857[0m
[BeforeEach] create remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3842
    DEBUG: 2019/07/11 14:26:46 START_TEST RemoteStorage.MultiSVDataVerification
    DEBUG: 2019/07/11 14:26:46 Login to cluster
    DEBUG: 2019/07/11 14:26:46 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 14:26:47 Checking basic Vnic usage
    DEBUG: 2019/07/11 14:26:47 Updating inventory struct
    DEBUG: 2019/07/11 14:26:53 Creating storage classes
[It] creates remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3857
    DEBUG: 2019/07/11 14:27:19 Computing total available storage space on node bosserv8
    DEBUG: 2019/07/11 14:27:19 Available space on the node is less than the maximum size of volume. Hence, creating a volume of size equal to maximum available space on node
Max Volume size allowed : 8796163276800
Available space on node : 3796751089664

    DEBUG: 2019/07/11 14:27:19 Creating the volume on node bosserv8
    DEBUG: 2019/07/11 14:27:20 Attaching the volume to node : bosserv9
    DEBUG: 2019/07/11 14:27:24 Getting sub volume load indices of the volume
    DEBUG: 2019/07/11 14:27:25 Volume "test-vol1" has sub volume load indices "[0 1]" in embedded.
    DEBUG: 2019/07/11 14:27:25 Verifying whether there are atleast 2 sub volumes for the volume
    DEBUG: 2019/07/11 14:27:25 Generating sub volume map
    DEBUG: 2019/07/11 14:27:27 Volume "test-vol1" has index "0" in embedded.
    DEBUG: 2019/07/11 14:27:30 Volume "test-vol1" has index "0" in embedded.
    DEBUG: 2019/07/11 14:27:31 Deleting existing fio state files from all the nodes
    DEBUG: 2019/07/11 14:27:32 Running write fio on volume from node : bosserv9
    DEBUG: 2019/07/11 14:27:32 Running Write IOs on node : bosserv9 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --iodepth=32 --bs=4K --gtod_reduce=1 --clat_percentiles=0 --numjobs=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --filename=/dev/nvme1n1  --rw=write --do_verify=0 --verify_state_save=1 --time_based --runtime=120 --name=job0 --offset=0 --io_limit=3435960729600 --name=job1 --offset=3435960729600 --io_limit=360854323200
    DEBUG: 2019/07/11 14:29:33 Getting the amount of writes on sub volumes
    DEBUG: 2019/07/11 14:29:35 Verifying whether there were writes on each sub volume
    DEBUG: 2019/07/11 14:29:35 Running verify fio on volume from node : bosserv9
    DEBUG: 2019/07/11 14:29:35 Running Verify IOs on node : bosserv9 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --iodepth=32 --bs=4K --gtod_reduce=1 --clat_percentiles=0 --numjobs=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --filename=/dev/nvme1n1  --rw=read --do_verify=1 --verify_state_load=1  --name=job0 --offset=0 --io_limit=3435960729600 --name=job1 --offset=3435960729600 --io_limit=360854323200
    DEBUG: 2019/07/11 14:32:20 Changing the ownership of .state files on node : bosserv9
    DEBUG: 2019/07/11 14:32:20 Copying .state files from node bosserv9 to controller node
    DEBUG: 2019/07/11 14:32:21 Copying .state files from controller node the non initiator node
    DEBUG: 2019/07/11 14:32:22 Detaching the volume from node bosserv9
    DEBUG: 2019/07/11 14:32:24 Attaching the volume to node : bosserv8
    DEBUG: 2019/07/11 14:32:28 Running verify fio on volume from node : bosserv8
    DEBUG: 2019/07/11 14:32:28 Running Verify IOs on node : bosserv8 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --iodepth=32 --bs=4K --gtod_reduce=1 --clat_percentiles=0 --numjobs=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --filename=/dev/nvme1n1  --rw=read --do_verify=1 --verify_state_load=1  --name=job0 --offset=0 --io_limit=3435960729600 --name=job1 --offset=3435960729600 --io_limit=360854323200
    DEBUG: 2019/07/11 14:33:26 Detach & Delete the volume
[AfterEach] create remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3852
    DEBUG: 2019/07/11 14:34:17 END_TEST RemoteStorage.MultiSVDataVerification Time-taken : 451.285768803

[32mâ€¢ [SLOW TEST:451.286 seconds][0m
RemoteStorage.MultiSVDataVerification Weekly RS_Verify-1.6
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3831[0m
  create remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3837[0m
    creates remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:3857[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mMirroring.ResyncInitiatorAndTargetReboot Weekly SM_Reboot-2.9[0m [90mreboot initiator and target nodes while IO is in progress and verify resync is successful[0m 
  [1mreboot initiator and target nodes while IO is in progress and verify resync is successful[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:539[0m
[BeforeEach] reboot initiator and target nodes while IO is in progress and verify resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:525
    DEBUG: 2019/07/11 14:34:17 START_TEST Mirroring.ResyncInitiatorAndTargetReboot
    DEBUG: 2019/07/11 14:34:17 Login to cluster
    DEBUG: 2019/07/11 14:34:17 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 14:34:18 Checking basic Vnic usage
    DEBUG: 2019/07/11 14:34:18 Updating inventory struct
    DEBUG: 2019/07/11 14:34:24 Creating storage classes
[It] reboot initiator and target nodes while IO is in progress and verify resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:539
    DEBUG: 2019/07/11 14:34:49 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2019/07/11 14:34:56 FBM and L1 usage is Zero across all nodes

    DEBUG: 2019/07/11 14:34:56 Assigning label to nodes where the plexes of mirrored volumes should get scheduled
    DEBUG: 2019/07/11 14:34:56 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 14:34:56 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 14:34:56 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 14:34:56 Creating 8 volumes of random sizes
    DEBUG: 2019/07/11 14:34:56 Mirror Count: 3
    DEBUG: 2019/07/11 14:35:05 Attaching all 8 volumes to node bosserv9
    DEBUG: 2019/07/11 14:35:36 Initiator node : bosserv9
    DEBUG: 2019/07/11 14:35:36 Nodes to reboot : bosserv9 bosserv8
    DEBUG: 2019/07/11 14:35:40 Running WRITE fio job on: bosserv9. FIO Command : echo -e '#!/bin/bash\n\nsudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"akpz\"-12 --verify_interval=4096 --runtime=400 --blocksize=512K --iodepth=8  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 > /tmp/fio_result.txt & > /dev/null 2>&1' > /tmp/fio_run.sh

    DEBUG: 2019/07/11 14:35:43 Number of running fio process: 11

    DEBUG: 2019/07/11 14:39:03 Getting cluster quorum nodes
    DEBUG: 2019/07/11 14:39:03 Powering OFF the node bosserv9
    DEBUG: 2019/07/11 14:39:09 Node 172.16.230.18 took 5 seconds to power off
    DEBUG: 2019/07/11 14:39:09 Powering OFF the node bosserv8
    DEBUG: 2019/07/11 14:39:15 Node 172.16.230.16 took 6 seconds to power off
    DEBUG: 2019/07/11 14:39:15 Ensuring that bosserv9 node is unreachable: 
    DEBUG: 2019/07/11 14:39:15 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 14:39:24 Ensuring that bosserv8 node is unreachable: 
    DEBUG: 2019/07/11 14:39:24 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 14:39:33 Powering ON the node bosserv9
    DEBUG: 2019/07/11 14:39:34 Node 172.16.230.18 took 1 seconds to power on
    DEBUG: 2019/07/11 14:39:34 Powering ON the node bosserv8
    DEBUG: 2019/07/11 14:39:35 Node 172.16.230.16 took 1 seconds to power on
    DEBUG: 2019/07/11 14:39:35 Checking if node bosserv9 is reachable or not: 
    DEBUG: 2019/07/11 14:39:35 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 14:39:54 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 14:40:11 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 14:40:28 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 14:40:45 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 14:40:49 bosserv9 is pingable from local machine
    DEBUG: 2019/07/11 14:40:49 Checking ssh port is up or not on node: bosserv9
    DEBUG: 2019/07/11 14:40:49 Checking if node bosserv8 is reachable or not: 
    DEBUG: 2019/07/11 14:40:49 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 14:40:53 bosserv8 is pingable from local machine
    DEBUG: 2019/07/11 14:40:53 Checking ssh port is up or not on node: bosserv8
    DEBUG: 2019/07/11 14:41:23 Waiting for the node(s) to come up and rejoin the cluster
    DEBUG: 2019/07/11 14:41:27 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:30 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:41:36 Found '3' nodes
    DEBUG: 2019/07/11 14:41:36 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 14:41:37 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 14:41:37 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 14:41:42 Error: . Retrying once again...
    DEBUG: 2019/07/11 14:42:05 After power cycle/reboot, updating timestamp of node : bosserv9
    DEBUG: 2019/07/11 14:42:07 After power cycle/reboot, updating timestamp of node : bosserv8
    DEBUG: 2019/07/11 14:42:10 Getting cluster quorum nodes
    DEBUG: 2019/07/11 14:42:10 Updating timestamp of master, because cluster was not in quorum majority
    DEBUG: 2019/07/11 14:43:13 Updating inventory struct
    DEBUG: 2019/07/11 14:43:13 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2019/07/11 14:43:24 Nodes are up, waiting for armada to start
.
    DEBUG: 2019/07/11 14:44:34 Waiting for the nodes to go into Ready state
    DEBUG: 2019/07/11 14:44:34 Found '3' nodes
    DEBUG: 2019/07/11 14:44:34 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 14:44:35 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 14:44:35 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 14:44:35 Waiting for volumes to come into Attached state after rebooting cluster nodes.
    DEBUG: 2019/07/11 14:44:38 Comparing Volume's UUID with nvme id-ns for all volumes
    DEBUG: 2019/07/11 14:44:42 Comparing the device path & uuid on initiator before and after target reboot
    DEBUG: 2019/07/11 14:44:42 Number of volumes : 8
    DEBUG: 2019/07/11 14:44:42 Checking resync progress on volume : test-vol8
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 All plexes of volume "test-vol8" are in "InUse" state.
    DEBUG: 2019/07/11 14:44:42 Checking resync progress on volume : test-vol4
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol4.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol4.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 All plexes of volume "test-vol4" are in "InUse" state.
    DEBUG: 2019/07/11 14:44:42 Checking resync progress on volume : test-vol3
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol3.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 All plexes of volume "test-vol3" are in "InUse" state.
    DEBUG: 2019/07/11 14:44:42 Checking resync progress on volume : test-vol2
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol2.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 All plexes of volume "test-vol2" are in "InUse" state.
    DEBUG: 2019/07/11 14:44:42 Checking resync progress on volume : test-vol6
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol6.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol6.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 All plexes of volume "test-vol6" are in "InUse" state.
    DEBUG: 2019/07/11 14:44:42 Checking resync progress on volume : test-vol1
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol1.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 All plexes of volume "test-vol1" are in "InUse" state.
    DEBUG: 2019/07/11 14:44:42 Checking resync progress on volume : test-vol5
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol5.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol5.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 All plexes of volume "test-vol5" are in "InUse" state.
    DEBUG: 2019/07/11 14:44:42 Checking resync progress on volume : test-vol7
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol7.p1. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 Volume name & Plex : test-vol7.p2. Plex State : InUse
    DEBUG: 2019/07/11 14:44:42 All plexes of volume "test-vol7" are in "InUse" state.
    DEBUG: 2019/07/11 14:44:48 Changing preferred plex of volume: test-vol1. Volume load index: 6.New preferred plex: 0
    DEBUG: 2019/07/11 14:44:49 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 14:44:50 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 14:44:51 Changing preferred plex of volume: test-vol4. Volume load index: 5.New preferred plex: 0
    DEBUG: 2019/07/11 14:44:52 Changing preferred plex of volume: test-vol5. Volume load index: 7.New preferred plex: 0
    DEBUG: 2019/07/11 14:44:53 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 14:44:54 Changing preferred plex of volume: test-vol7. Volume load index: 3.New preferred plex: 0
    DEBUG: 2019/07/11 14:44:56 Changing preferred plex of volume: test-vol8. Volume load index: 4.New preferred plex: 0
    DEBUG: 2019/07/11 14:44:56 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2019/07/11 14:44:56 Calculating cksum for volume test-vol2 and plex p0
    DEBUG: 2019/07/11 14:44:56 Calculating cksum for volume test-vol3 and plex p0
    DEBUG: 2019/07/11 14:44:56 Calculating cksum for volume test-vol4 and plex p0
    DEBUG: 2019/07/11 14:44:56 Calculating cksum for volume test-vol5 and plex p0
    DEBUG: 2019/07/11 14:44:56 Calculating cksum for volume test-vol6 and plex p0
    DEBUG: 2019/07/11 14:44:56 Calculating cksum for volume test-vol7 and plex p0
    DEBUG: 2019/07/11 14:44:57 Calculating cksum for volume test-vol8 and plex p0
    DEBUG: 2019/07/11 14:49:16 Changing preferred plex of volume: test-vol1. Volume load index: 6.New preferred plex: 1
    DEBUG: 2019/07/11 14:49:17 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 14:49:19 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 14:49:20 Changing preferred plex of volume: test-vol4. Volume load index: 5.New preferred plex: 1
    DEBUG: 2019/07/11 14:49:21 Changing preferred plex of volume: test-vol5. Volume load index: 7.New preferred plex: 1
    DEBUG: 2019/07/11 14:49:22 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 14:49:23 Changing preferred plex of volume: test-vol7. Volume load index: 3.New preferred plex: 1
    DEBUG: 2019/07/11 14:49:24 Changing preferred plex of volume: test-vol8. Volume load index: 4.New preferred plex: 1
    DEBUG: 2019/07/11 14:49:25 Calculating cksum for volume test-vol1 and plex p1
    DEBUG: 2019/07/11 14:49:25 Calculating cksum for volume test-vol2 and plex p1
    DEBUG: 2019/07/11 14:49:25 Calculating cksum for volume test-vol3 and plex p1
    DEBUG: 2019/07/11 14:49:25 Calculating cksum for volume test-vol4 and plex p1
    DEBUG: 2019/07/11 14:49:25 Calculating cksum for volume test-vol5 and plex p1
    DEBUG: 2019/07/11 14:49:25 Calculating cksum for volume test-vol6 and plex p1
    DEBUG: 2019/07/11 14:49:25 Calculating cksum for volume test-vol7 and plex p1
    DEBUG: 2019/07/11 14:49:25 Calculating cksum for volume test-vol8 and plex p1
    DEBUG: 2019/07/11 14:53:22 Changing preferred plex of volume: test-vol1. Volume load index: 6.New preferred plex: 2
    DEBUG: 2019/07/11 14:53:23 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 14:53:24 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 2
    DEBUG: 2019/07/11 14:53:25 Changing preferred plex of volume: test-vol4. Volume load index: 5.New preferred plex: 2
    DEBUG: 2019/07/11 14:53:26 Changing preferred plex of volume: test-vol5. Volume load index: 7.New preferred plex: 2
    DEBUG: 2019/07/11 14:53:27 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 14:53:28 Changing preferred plex of volume: test-vol7. Volume load index: 3.New preferred plex: 2
    DEBUG: 2019/07/11 14:53:29 Changing preferred plex of volume: test-vol8. Volume load index: 4.New preferred plex: 2
    DEBUG: 2019/07/11 14:53:30 Calculating cksum for volume test-vol1 and plex p2
    DEBUG: 2019/07/11 14:53:30 Calculating cksum for volume test-vol2 and plex p2
    DEBUG: 2019/07/11 14:53:30 Calculating cksum for volume test-vol3 and plex p2
    DEBUG: 2019/07/11 14:53:30 Calculating cksum for volume test-vol4 and plex p2
    DEBUG: 2019/07/11 14:53:30 Calculating cksum for volume test-vol5 and plex p2
    DEBUG: 2019/07/11 14:53:30 Calculating cksum for volume test-vol6 and plex p2
    DEBUG: 2019/07/11 14:53:30 Calculating cksum for volume test-vol7 and plex p2
    DEBUG: 2019/07/11 14:53:30 Calculating cksum for volume test-vol8 and plex p2
    DEBUG: 2019/07/11 14:57:20 Successfully completed Verification on all the plexes
    DEBUG: 2019/07/11 14:57:20 Detach & Delete all volumes
    DEBUG: 2019/07/11 14:58:39 Removing label from the nodes where the plexes of mirrored volumes were scheduled
    DEBUG: 2019/07/11 14:58:39 Removed label : mirror from node : bosserv8
    DEBUG: 2019/07/11 14:58:39 Removed label : mirror from node : bosserv9
    DEBUG: 2019/07/11 14:58:39 Removed label : mirror from node : bosserv7
[AfterEach] reboot initiator and target nodes while IO is in progress and verify resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:534
    DEBUG: 2019/07/11 14:58:39 END_TEST Mirroring.ResyncInitiatorAndTargetReboot Time-taken : 1461.930177817

[32mâ€¢ [SLOW TEST:1461.930 seconds][0m
Mirroring.ResyncInitiatorAndTargetReboot Weekly SM_Reboot-2.9
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:518[0m
  reboot initiator and target nodes while IO is in progress and verify resync is successful
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:520[0m
    reboot initiator and target nodes while IO is in progress and verify resync is successful
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:539[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mMirroring.StressWithIO Weekly SM_Stress-1.6 SM_Stress-1.7 SM_Stress-1.9 SM_Stress-1.10[0m [90mcreate maximum mirrored volumes and run attach, IOs, detach delete in a loop[0m 
  [1mcreates maximum mirrored volumes and runs attach, IOs, detach delete in a loop[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:400[0m
[BeforeEach] create maximum mirrored volumes and run attach, IOs, detach delete in a loop
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:386
    DEBUG: 2019/07/11 14:58:39 START_TEST Mirroring.StressWithIO
    DEBUG: 2019/07/11 14:58:39 Login to cluster
    DEBUG: 2019/07/11 14:58:39 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 14:58:40 Checking basic Vnic usage
    DEBUG: 2019/07/11 14:58:40 Updating inventory struct
    DEBUG: 2019/07/11 14:58:46 Creating storage classes
[It] creates maximum mirrored volumes and runs attach, IOs, detach delete in a loop
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:400
    DEBUG: 2019/07/11 14:59:13 Running Create - Attach - Write IO - Detach - Delete volumes in a loop
    DEBUG: 2019/07/11 14:59:13 Running iteration no : 1
    DEBUG: 2019/07/11 14:59:13 Assigning mirror label to nodes : [bosserv8 bosserv9] to schedule mirrored volume plexes
    DEBUG: 2019/07/11 14:59:13 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 14:59:13 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 14:59:13 Creating volumes on the nodes : [bosserv8 bosserv9]
    DEBUG: 2019/07/11 14:59:32 Removing mirror label from the nodes : [bosserv8 bosserv9]
    DEBUG: 2019/07/11 14:59:32 Removed label : mirror from node : bosserv8
    DEBUG: 2019/07/11 14:59:32 Removed label : mirror from node : bosserv9
    DEBUG: 2019/07/11 14:59:32 Attaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 14:59:32 Attaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:00:36 Running WRITE IOs with IO Size (128K) & IO Depth (32)
    DEBUG: 2019/07/11 15:00:37 Running Write IOs on node : bosserv8 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --runtime=180 --time_based --numjobs=8  --blocksize=128K --iodepth=32  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:00:37 Running Write IOs on node : bosserv9 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --runtime=180 --time_based --numjobs=8  --blocksize=128K --iodepth=32  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:03:40 Successfully completed fio jobs on cluster nodes.
    DEBUG: 2019/07/11 15:03:40 Detaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:03:40 Detaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:03:45 Deleting volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:03:45 Deleting volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:04:41 Checking Drive Usage on node : bosserv8
    DEBUG: 2019/07/11 15:04:41 Checking Drive Usage on node : bosserv9
    DEBUG: 2019/07/11 15:04:41 Checking Drive Usage on node : bosserv7
    DEBUG: 2019/07/11 15:04:41 Running iteration no : 2
    DEBUG: 2019/07/11 15:04:41 Assigning mirror label to nodes : [bosserv9 bosserv7] to schedule mirrored volume plexes
    DEBUG: 2019/07/11 15:04:41 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 15:04:41 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 15:04:41 Creating volumes on the nodes : [bosserv9 bosserv7]
    DEBUG: 2019/07/11 15:05:00 Removing mirror label from the nodes : [bosserv9 bosserv7]
    DEBUG: 2019/07/11 15:05:00 Removed label : mirror from node : bosserv9
    DEBUG: 2019/07/11 15:05:00 Removed label : mirror from node : bosserv7
    DEBUG: 2019/07/11 15:05:00 Attaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:05:00 Attaching volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:06:03 Running WRITE IOs with BS Range (4K to 1M) & IO Depth (16)
    DEBUG: 2019/07/11 15:06:03 Running Write IOs on node : bosserv7 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --runtime=180 --time_based --numjobs=8  --blocksize_range=4K-1024K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:06:03 Running Write IOs on node : bosserv9 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --runtime=180 --time_based --numjobs=8  --blocksize_range=4K-1024K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:09:08 Successfully completed fio jobs on cluster nodes.
    DEBUG: 2019/07/11 15:09:08 Detaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:09:08 Detaching volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:09:12 Deleting volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:09:12 Deleting volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:10:12 Checking Drive Usage on node : bosserv8
    DEBUG: 2019/07/11 15:10:12 Checking Drive Usage on node : bosserv9
    DEBUG: 2019/07/11 15:10:12 Checking Drive Usage on node : bosserv7
    DEBUG: 2019/07/11 15:10:12 Running iteration no : 3
    DEBUG: 2019/07/11 15:10:12 Assigning mirror label to nodes : [bosserv7 bosserv8] to schedule mirrored volume plexes
    DEBUG: 2019/07/11 15:10:12 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 15:10:12 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 15:10:12 Creating volumes on the nodes : [bosserv7 bosserv8]
    DEBUG: 2019/07/11 15:10:31 Removing mirror label from the nodes : [bosserv7 bosserv8]
    DEBUG: 2019/07/11 15:10:31 Removed label : mirror from node : bosserv7
    DEBUG: 2019/07/11 15:10:31 Removed label : mirror from node : bosserv8
    DEBUG: 2019/07/11 15:10:31 Attaching volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:10:31 Attaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:11:34 Running WRITE IOs with BS Range (32K to 1024K) & IO Depth (8)
    DEBUG: 2019/07/11 15:11:35 Running Write IOs on node : bosserv7 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --runtime=180 --time_based --numjobs=8  --blocksize_range=32K-1024K --iodepth=8  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:11:35 Running Write IOs on node : bosserv8 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --runtime=180 --time_based --numjobs=8  --blocksize_range=32K-1024K --iodepth=8  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:14:39 Successfully completed fio jobs on cluster nodes.
    DEBUG: 2019/07/11 15:14:39 Detaching volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:14:39 Detaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:14:43 Deleting volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:14:43 Deleting volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:15:41 Checking Drive Usage on node : bosserv7
    DEBUG: 2019/07/11 15:15:41 Checking Drive Usage on node : bosserv8
    DEBUG: 2019/07/11 15:15:41 Checking Drive Usage on node : bosserv9
    DEBUG: 2019/07/11 15:15:41 /**** Completed Operations: Create - Attach - Write IO - Detach - Delete volumes in a loop. Total Iterations: 3 ****/
    DEBUG: 2019/07/11 15:15:41 Running Attach - Detach volumes in a loop
    DEBUG: 2019/07/11 15:15:41 Assigning mirror label to nodes : [bosserv8 bosserv9] to schedule mirrored volume plexes
    DEBUG: 2019/07/11 15:15:41 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 15:15:41 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 15:15:41 Creating volumes on the nodes : [bosserv8 bosserv9]
    DEBUG: 2019/07/11 15:16:00 Removing mirror label from the nodes : [bosserv8 bosserv9]
    DEBUG: 2019/07/11 15:16:00 Removed label : mirror from node : bosserv8
    DEBUG: 2019/07/11 15:16:00 Removed label : mirror from node : bosserv9
    DEBUG: 2019/07/11 15:16:00 Running iteration no : 1
    DEBUG: 2019/07/11 15:16:00 Attaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:16:00 Attaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:17:03 Detaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:17:03 Detaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:17:07 Running iteration no : 2
    DEBUG: 2019/07/11 15:17:07 Attaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:17:07 Attaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:18:11 Detaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:18:11 Detaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:18:37 Running iteration no : 3
    DEBUG: 2019/07/11 15:18:37 Attaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:18:37 Attaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:19:41 Detaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:19:41 Detaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:20:07 Deleting volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:20:07 Deleting volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:20:42 Checking Drive Usage on node : bosserv7
    DEBUG: 2019/07/11 15:20:42 Checking Drive Usage on node : bosserv8
    DEBUG: 2019/07/11 15:20:42 Checking Drive Usage on node : bosserv9
    DEBUG: 2019/07/11 15:20:42 /**** Completed Operations: Attach - Detach volumes in a loop. Total Iterations: 3 ****/
    DEBUG: 2019/07/11 15:20:42 Running Create - Attach - Write IO - Verify IO - Detach - Delete volumes in a loop
    DEBUG: 2019/07/11 15:20:42 Running iteration no : 1
    DEBUG: 2019/07/11 15:20:42 Assigning mirror label to nodes : [bosserv8 bosserv9] to schedule mirrored volume plexes
    DEBUG: 2019/07/11 15:20:42 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 15:20:42 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 15:20:42 Creating volumes on the nodes : [bosserv8 bosserv9]
    DEBUG: 2019/07/11 15:21:01 Removing mirror label from the nodes : [bosserv8 bosserv9]
    DEBUG: 2019/07/11 15:21:01 Removed label : mirror from node : bosserv8
    DEBUG: 2019/07/11 15:21:01 Removed label : mirror from node : bosserv9
    DEBUG: 2019/07/11 15:21:01 Attaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:21:01 Attaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:22:05 Running WRITE IOs with IO Size (4K) & IO Depth (32)
    DEBUG: 2019/07/11 15:22:06 Running Write IOs on node : bosserv8 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --runtime=180 --time_based  --blocksize=4K --iodepth=32  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:22:06 Running Write IOs on node : bosserv9 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --runtime=180 --time_based  --blocksize=4K --iodepth=32  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:25:08 Successfully completed fio jobs on cluster nodes.
    DEBUG: 2019/07/11 15:25:08 Running VERIFY IOs on all plexes with IO Size (4K) & IO Depth (32)
    DEBUG: 2019/07/11 15:25:09 Changing preferred plex of volume: bosserv8-test-vol1. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:09 Changing preferred plex of volume: bosserv9-test-vol1. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:11 Changing preferred plex of volume: bosserv8-test-vol10. Volume load index: 19.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:11 Changing preferred plex of volume: bosserv9-test-vol10. Volume load index: 18.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:12 Changing preferred plex of volume: bosserv8-test-vol11. Volume load index: 21.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:12 Changing preferred plex of volume: bosserv9-test-vol11. Volume load index: 20.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:13 Changing preferred plex of volume: bosserv8-test-vol12. Volume load index: 23.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:13 Changing preferred plex of volume: bosserv9-test-vol12. Volume load index: 22.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:14 Changing preferred plex of volume: bosserv9-test-vol13. Volume load index: 24.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:14 Changing preferred plex of volume: bosserv8-test-vol13. Volume load index: 24.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:15 Changing preferred plex of volume: bosserv9-test-vol14. Volume load index: 26.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:15 Changing preferred plex of volume: bosserv8-test-vol14. Volume load index: 27.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:16 Changing preferred plex of volume: bosserv9-test-vol15. Volume load index: 28.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:16 Changing preferred plex of volume: bosserv8-test-vol15. Volume load index: 29.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:17 Changing preferred plex of volume: bosserv9-test-vol16. Volume load index: 30.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:17 Changing preferred plex of volume: bosserv8-test-vol16. Volume load index: 31.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:18 Changing preferred plex of volume: bosserv9-test-vol2. Volume load index: 3.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:18 Changing preferred plex of volume: bosserv8-test-vol2. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:20 Changing preferred plex of volume: bosserv9-test-vol3. Volume load index: 5.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:20 Changing preferred plex of volume: bosserv8-test-vol3. Volume load index: 4.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:21 Changing preferred plex of volume: bosserv9-test-vol4. Volume load index: 7.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:21 Changing preferred plex of volume: bosserv8-test-vol4. Volume load index: 6.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:22 Changing preferred plex of volume: bosserv9-test-vol5. Volume load index: 9.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:22 Changing preferred plex of volume: bosserv8-test-vol5. Volume load index: 8.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:23 Changing preferred plex of volume: bosserv9-test-vol6. Volume load index: 10.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:23 Changing preferred plex of volume: bosserv8-test-vol6. Volume load index: 10.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:24 Changing preferred plex of volume: bosserv9-test-vol7. Volume load index: 12.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:24 Changing preferred plex of volume: bosserv8-test-vol7. Volume load index: 12.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:25 Changing preferred plex of volume: bosserv9-test-vol8. Volume load index: 14.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:25 Changing preferred plex of volume: bosserv8-test-vol8. Volume load index: 15.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:26 Changing preferred plex of volume: bosserv9-test-vol9. Volume load index: 16.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:26 Changing preferred plex of volume: bosserv8-test-vol9. Volume load index: 17.New preferred plex: 0
    DEBUG: 2019/07/11 15:25:27 Running Verify IOs on node : bosserv9 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --iodepth=32  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:25:27 Running Verify IOs on node : bosserv8 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --iodepth=32  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:26:30 Changing preferred plex of volume: bosserv8-test-vol1. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:31 Changing preferred plex of volume: bosserv8-test-vol10. Volume load index: 19.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:32 Changing preferred plex of volume: bosserv8-test-vol11. Volume load index: 21.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:33 Changing preferred plex of volume: bosserv8-test-vol12. Volume load index: 23.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:34 Changing preferred plex of volume: bosserv8-test-vol13. Volume load index: 24.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:34 Changing preferred plex of volume: bosserv9-test-vol1. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:35 Changing preferred plex of volume: bosserv8-test-vol14. Volume load index: 27.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:36 Changing preferred plex of volume: bosserv9-test-vol10. Volume load index: 18.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:36 Changing preferred plex of volume: bosserv8-test-vol15. Volume load index: 29.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:37 Changing preferred plex of volume: bosserv9-test-vol11. Volume load index: 20.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:38 Changing preferred plex of volume: bosserv8-test-vol16. Volume load index: 31.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:38 Changing preferred plex of volume: bosserv9-test-vol12. Volume load index: 22.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:39 Changing preferred plex of volume: bosserv8-test-vol2. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:39 Changing preferred plex of volume: bosserv9-test-vol13. Volume load index: 24.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:40 Changing preferred plex of volume: bosserv8-test-vol3. Volume load index: 4.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:40 Changing preferred plex of volume: bosserv9-test-vol14. Volume load index: 26.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:41 Changing preferred plex of volume: bosserv8-test-vol4. Volume load index: 6.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:41 Changing preferred plex of volume: bosserv9-test-vol15. Volume load index: 28.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:42 Changing preferred plex of volume: bosserv8-test-vol5. Volume load index: 8.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:42 Changing preferred plex of volume: bosserv9-test-vol16. Volume load index: 30.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:43 Changing preferred plex of volume: bosserv8-test-vol6. Volume load index: 10.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:43 Changing preferred plex of volume: bosserv9-test-vol2. Volume load index: 3.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:44 Changing preferred plex of volume: bosserv8-test-vol7. Volume load index: 12.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:45 Changing preferred plex of volume: bosserv9-test-vol3. Volume load index: 5.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:45 Changing preferred plex of volume: bosserv8-test-vol8. Volume load index: 15.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:46 Changing preferred plex of volume: bosserv9-test-vol4. Volume load index: 7.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:47 Changing preferred plex of volume: bosserv8-test-vol9. Volume load index: 17.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:47 Changing preferred plex of volume: bosserv9-test-vol5. Volume load index: 9.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:47 Running Verify IOs on node : bosserv8 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --iodepth=32  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:26:48 Changing preferred plex of volume: bosserv9-test-vol6. Volume load index: 10.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:49 Changing preferred plex of volume: bosserv9-test-vol7. Volume load index: 12.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:50 Changing preferred plex of volume: bosserv9-test-vol8. Volume load index: 14.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:51 Changing preferred plex of volume: bosserv9-test-vol9. Volume load index: 16.New preferred plex: 1
    DEBUG: 2019/07/11 15:26:52 Running Verify IOs on node : bosserv9 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --iodepth=32  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:28:29 Successfully completed fio jobs on cluster nodes.
    DEBUG: 2019/07/11 15:28:29 Detaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:28:29 Detaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:28:34 Deleting volumes on the node : bosserv9
    DEBUG: 2019/07/11 15:28:34 Deleting volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:29:44 Running iteration no : 2
    DEBUG: 2019/07/11 15:29:44 Assigning mirror label to nodes : [bosserv7 bosserv8] to schedule mirrored volume plexes
    DEBUG: 2019/07/11 15:29:44 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 15:29:44 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 15:29:44 Creating volumes on the nodes : [bosserv7 bosserv8]
    DEBUG: 2019/07/11 15:30:03 Removing mirror label from the nodes : [bosserv7 bosserv8]
    DEBUG: 2019/07/11 15:30:03 Removed label : mirror from node : bosserv7
    DEBUG: 2019/07/11 15:30:03 Removed label : mirror from node : bosserv8
    DEBUG: 2019/07/11 15:30:03 Attaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:30:03 Attaching volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:31:07 Running WRITE IOs with IO Size (64K) & IO Depth (16)
    DEBUG: 2019/07/11 15:31:08 Running Write IOs on node : bosserv7 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096 --runtime=180 --time_based  --blocksize=64K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:31:08 Running Write IOs on node : bosserv8 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096 --runtime=180 --time_based  --blocksize=64K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:34:09 Successfully completed fio jobs on cluster nodes.
    DEBUG: 2019/07/11 15:34:09 Running VERIFY IOs on all plexes with IO Size (64K) & IO Depth (16)
    DEBUG: 2019/07/11 15:34:11 Changing preferred plex of volume: bosserv7-test-vol1. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:11 Changing preferred plex of volume: bosserv8-test-vol1. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:12 Changing preferred plex of volume: bosserv8-test-vol10. Volume load index: 19.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:12 Changing preferred plex of volume: bosserv7-test-vol10. Volume load index: 18.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:13 Changing preferred plex of volume: bosserv7-test-vol11. Volume load index: 20.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:13 Changing preferred plex of volume: bosserv8-test-vol11. Volume load index: 20.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:14 Changing preferred plex of volume: bosserv7-test-vol12. Volume load index: 23.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:14 Changing preferred plex of volume: bosserv8-test-vol12. Volume load index: 22.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:15 Changing preferred plex of volume: bosserv7-test-vol13. Volume load index: 24.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:15 Changing preferred plex of volume: bosserv8-test-vol13. Volume load index: 24.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:17 Changing preferred plex of volume: bosserv8-test-vol14. Volume load index: 26.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:17 Changing preferred plex of volume: bosserv7-test-vol14. Volume load index: 27.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:18 Changing preferred plex of volume: bosserv7-test-vol15. Volume load index: 29.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:18 Changing preferred plex of volume: bosserv8-test-vol15. Volume load index: 28.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:19 Changing preferred plex of volume: bosserv7-test-vol16. Volume load index: 31.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:19 Changing preferred plex of volume: bosserv8-test-vol16. Volume load index: 30.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:20 Changing preferred plex of volume: bosserv7-test-vol2. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:20 Changing preferred plex of volume: bosserv8-test-vol2. Volume load index: 3.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:21 Changing preferred plex of volume: bosserv7-test-vol3. Volume load index: 4.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:21 Changing preferred plex of volume: bosserv8-test-vol3. Volume load index: 5.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:22 Changing preferred plex of volume: bosserv8-test-vol4. Volume load index: 7.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:22 Changing preferred plex of volume: bosserv7-test-vol4. Volume load index: 6.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:23 Changing preferred plex of volume: bosserv8-test-vol5. Volume load index: 9.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:23 Changing preferred plex of volume: bosserv7-test-vol5. Volume load index: 8.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:24 Changing preferred plex of volume: bosserv8-test-vol6. Volume load index: 11.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:24 Changing preferred plex of volume: bosserv7-test-vol6. Volume load index: 10.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:26 Changing preferred plex of volume: bosserv8-test-vol7. Volume load index: 13.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:26 Changing preferred plex of volume: bosserv7-test-vol7. Volume load index: 12.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:27 Changing preferred plex of volume: bosserv8-test-vol8. Volume load index: 15.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:27 Changing preferred plex of volume: bosserv7-test-vol8. Volume load index: 14.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:28 Changing preferred plex of volume: bosserv8-test-vol9. Volume load index: 17.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:28 Changing preferred plex of volume: bosserv7-test-vol9. Volume load index: 16.New preferred plex: 0
    DEBUG: 2019/07/11 15:34:28 Running Verify IOs on node : bosserv8 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=64K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:34:28 Running Verify IOs on node : bosserv7 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=64K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:35:50 Changing preferred plex of volume: bosserv7-test-vol1. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 15:35:51 Changing preferred plex of volume: bosserv7-test-vol10. Volume load index: 18.New preferred plex: 1
    DEBUG: 2019/07/11 15:35:52 Changing preferred plex of volume: bosserv7-test-vol11. Volume load index: 20.New preferred plex: 1
    DEBUG: 2019/07/11 15:35:53 Changing preferred plex of volume: bosserv7-test-vol12. Volume load index: 23.New preferred plex: 1
    DEBUG: 2019/07/11 15:35:54 Changing preferred plex of volume: bosserv7-test-vol13. Volume load index: 24.New preferred plex: 1
    DEBUG: 2019/07/11 15:35:55 Changing preferred plex of volume: bosserv7-test-vol14. Volume load index: 27.New preferred plex: 1
    DEBUG: 2019/07/11 15:35:56 Changing preferred plex of volume: bosserv7-test-vol15. Volume load index: 29.New preferred plex: 1
    DEBUG: 2019/07/11 15:35:58 Changing preferred plex of volume: bosserv7-test-vol16. Volume load index: 31.New preferred plex: 1
    DEBUG: 2019/07/11 15:35:59 Changing preferred plex of volume: bosserv7-test-vol2. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:00 Changing preferred plex of volume: bosserv7-test-vol3. Volume load index: 4.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:01 Changing preferred plex of volume: bosserv7-test-vol4. Volume load index: 6.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:02 Changing preferred plex of volume: bosserv7-test-vol5. Volume load index: 8.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:03 Changing preferred plex of volume: bosserv8-test-vol1. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:03 Changing preferred plex of volume: bosserv7-test-vol6. Volume load index: 10.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:04 Changing preferred plex of volume: bosserv7-test-vol7. Volume load index: 12.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:04 Changing preferred plex of volume: bosserv8-test-vol10. Volume load index: 19.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:05 Changing preferred plex of volume: bosserv7-test-vol8. Volume load index: 14.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:05 Changing preferred plex of volume: bosserv8-test-vol11. Volume load index: 20.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:06 Changing preferred plex of volume: bosserv7-test-vol9. Volume load index: 16.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:06 Changing preferred plex of volume: bosserv8-test-vol12. Volume load index: 22.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:07 Running Verify IOs on node : bosserv7 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=64K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:36:08 Changing preferred plex of volume: bosserv8-test-vol13. Volume load index: 24.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:09 Changing preferred plex of volume: bosserv8-test-vol14. Volume load index: 26.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:10 Changing preferred plex of volume: bosserv8-test-vol15. Volume load index: 28.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:11 Changing preferred plex of volume: bosserv8-test-vol16. Volume load index: 30.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:12 Changing preferred plex of volume: bosserv8-test-vol2. Volume load index: 3.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:13 Changing preferred plex of volume: bosserv8-test-vol3. Volume load index: 5.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:14 Changing preferred plex of volume: bosserv8-test-vol4. Volume load index: 7.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:15 Changing preferred plex of volume: bosserv8-test-vol5. Volume load index: 9.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:16 Changing preferred plex of volume: bosserv8-test-vol6. Volume load index: 11.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:18 Changing preferred plex of volume: bosserv8-test-vol7. Volume load index: 13.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:19 Changing preferred plex of volume: bosserv8-test-vol8. Volume load index: 15.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:20 Changing preferred plex of volume: bosserv8-test-vol9. Volume load index: 17.New preferred plex: 1
    DEBUG: 2019/07/11 15:36:20 Running Verify IOs on node : bosserv8 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=64K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:37:39 Successfully completed fio jobs on cluster nodes.
    DEBUG: 2019/07/11 15:37:39 Detaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:37:39 Detaching volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:37:44 Deleting volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:37:44 Deleting volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:38:46 Running iteration no : 3
    DEBUG: 2019/07/11 15:38:46 Assigning mirror label to nodes : [bosserv7 bosserv8] to schedule mirrored volume plexes
    DEBUG: 2019/07/11 15:38:46 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 15:38:46 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 15:38:46 Creating volumes on the nodes : [bosserv7 bosserv8]
    DEBUG: 2019/07/11 15:39:05 Removing mirror label from the nodes : [bosserv7 bosserv8]
    DEBUG: 2019/07/11 15:39:05 Removed label : mirror from node : bosserv7
    DEBUG: 2019/07/11 15:39:05 Removed label : mirror from node : bosserv8
    DEBUG: 2019/07/11 15:39:05 Attaching volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:39:05 Attaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:40:07 Running WRITE IOs with IO Size (512K) & IO Depth (8)
    DEBUG: 2019/07/11 15:40:08 Running Write IOs on node : bosserv7 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"wxyz\"-12 --verify_interval=4096 --runtime=180 --time_based  --blocksize=512K --iodepth=8  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:40:08 Running Write IOs on node : bosserv8 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"wxyz\"-12 --verify_interval=4096 --runtime=180 --time_based  --blocksize=512K --iodepth=8  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:43:10 Successfully completed fio jobs on cluster nodes.
    DEBUG: 2019/07/11 15:43:10 Running VERIFY IOs on all plexes with IO Size (512K) & IO Depth (8)
    DEBUG: 2019/07/11 15:43:12 Changing preferred plex of volume: bosserv8-test-vol1. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:12 Changing preferred plex of volume: bosserv7-test-vol1. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:13 Changing preferred plex of volume: bosserv8-test-vol10. Volume load index: 18.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:13 Changing preferred plex of volume: bosserv7-test-vol10. Volume load index: 18.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:14 Changing preferred plex of volume: bosserv8-test-vol11. Volume load index: 20.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:14 Changing preferred plex of volume: bosserv7-test-vol11. Volume load index: 21.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:15 Changing preferred plex of volume: bosserv8-test-vol12. Volume load index: 22.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:15 Changing preferred plex of volume: bosserv7-test-vol12. Volume load index: 23.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:16 Changing preferred plex of volume: bosserv7-test-vol13. Volume load index: 25.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:16 Changing preferred plex of volume: bosserv8-test-vol13. Volume load index: 24.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:17 Changing preferred plex of volume: bosserv7-test-vol14. Volume load index: 27.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:17 Changing preferred plex of volume: bosserv8-test-vol14. Volume load index: 26.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:18 Changing preferred plex of volume: bosserv8-test-vol15. Volume load index: 28.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:18 Changing preferred plex of volume: bosserv7-test-vol15. Volume load index: 29.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:19 Changing preferred plex of volume: bosserv8-test-vol16. Volume load index: 30.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:20 Changing preferred plex of volume: bosserv7-test-vol16. Volume load index: 31.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:21 Changing preferred plex of volume: bosserv8-test-vol2. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:21 Changing preferred plex of volume: bosserv7-test-vol2. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:22 Changing preferred plex of volume: bosserv8-test-vol3. Volume load index: 4.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:22 Changing preferred plex of volume: bosserv7-test-vol3. Volume load index: 5.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:23 Changing preferred plex of volume: bosserv8-test-vol4. Volume load index: 6.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:23 Changing preferred plex of volume: bosserv7-test-vol4. Volume load index: 7.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:24 Changing preferred plex of volume: bosserv7-test-vol5. Volume load index: 9.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:24 Changing preferred plex of volume: bosserv8-test-vol5. Volume load index: 8.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:25 Changing preferred plex of volume: bosserv8-test-vol6. Volume load index: 10.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:25 Changing preferred plex of volume: bosserv7-test-vol6. Volume load index: 11.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:26 Changing preferred plex of volume: bosserv8-test-vol7. Volume load index: 12.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:26 Changing preferred plex of volume: bosserv7-test-vol7. Volume load index: 13.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:27 Changing preferred plex of volume: bosserv8-test-vol8. Volume load index: 14.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:27 Changing preferred plex of volume: bosserv7-test-vol8. Volume load index: 15.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:29 Changing preferred plex of volume: bosserv8-test-vol9. Volume load index: 16.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:29 Changing preferred plex of volume: bosserv7-test-vol9. Volume load index: 17.New preferred plex: 0
    DEBUG: 2019/07/11 15:43:29 Running Verify IOs on node : bosserv8 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"wxyz\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=512K --iodepth=8  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:43:29 Running Verify IOs on node : bosserv7 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"wxyz\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=512K --iodepth=8  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:44:43 Changing preferred plex of volume: bosserv7-test-vol1. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:44 Changing preferred plex of volume: bosserv7-test-vol10. Volume load index: 18.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:45 Changing preferred plex of volume: bosserv7-test-vol11. Volume load index: 21.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:46 Changing preferred plex of volume: bosserv7-test-vol12. Volume load index: 23.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:47 Changing preferred plex of volume: bosserv7-test-vol13. Volume load index: 25.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:48 Changing preferred plex of volume: bosserv7-test-vol14. Volume load index: 27.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:49 Changing preferred plex of volume: bosserv7-test-vol15. Volume load index: 29.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:50 Changing preferred plex of volume: bosserv7-test-vol16. Volume load index: 31.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:51 Changing preferred plex of volume: bosserv7-test-vol2. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:52 Changing preferred plex of volume: bosserv7-test-vol3. Volume load index: 5.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:54 Changing preferred plex of volume: bosserv7-test-vol4. Volume load index: 7.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:55 Changing preferred plex of volume: bosserv7-test-vol5. Volume load index: 9.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:56 Changing preferred plex of volume: bosserv7-test-vol6. Volume load index: 11.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:57 Changing preferred plex of volume: bosserv7-test-vol7. Volume load index: 13.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:58 Changing preferred plex of volume: bosserv7-test-vol8. Volume load index: 15.New preferred plex: 1
    DEBUG: 2019/07/11 15:44:59 Changing preferred plex of volume: bosserv7-test-vol9. Volume load index: 17.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:00 Running Verify IOs on node : bosserv7 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"wxyz\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=512K --iodepth=8  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:45:48 Changing preferred plex of volume: bosserv8-test-vol1. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:49 Changing preferred plex of volume: bosserv8-test-vol10. Volume load index: 18.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:50 Changing preferred plex of volume: bosserv8-test-vol11. Volume load index: 20.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:51 Changing preferred plex of volume: bosserv8-test-vol12. Volume load index: 22.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:52 Changing preferred plex of volume: bosserv8-test-vol13. Volume load index: 24.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:53 Changing preferred plex of volume: bosserv8-test-vol14. Volume load index: 26.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:54 Changing preferred plex of volume: bosserv8-test-vol15. Volume load index: 28.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:56 Changing preferred plex of volume: bosserv8-test-vol16. Volume load index: 30.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:57 Changing preferred plex of volume: bosserv8-test-vol2. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:58 Changing preferred plex of volume: bosserv8-test-vol3. Volume load index: 4.New preferred plex: 1
    DEBUG: 2019/07/11 15:45:59 Changing preferred plex of volume: bosserv8-test-vol4. Volume load index: 6.New preferred plex: 1
    DEBUG: 2019/07/11 15:46:00 Changing preferred plex of volume: bosserv8-test-vol5. Volume load index: 8.New preferred plex: 1
    DEBUG: 2019/07/11 15:46:01 Changing preferred plex of volume: bosserv8-test-vol6. Volume load index: 10.New preferred plex: 1
    DEBUG: 2019/07/11 15:46:02 Changing preferred plex of volume: bosserv8-test-vol7. Volume load index: 12.New preferred plex: 1
    DEBUG: 2019/07/11 15:46:03 Changing preferred plex of volume: bosserv8-test-vol8. Volume load index: 14.New preferred plex: 1
    DEBUG: 2019/07/11 15:46:05 Changing preferred plex of volume: bosserv8-test-vol9. Volume load index: 16.New preferred plex: 1
    DEBUG: 2019/07/11 15:46:05 Running Verify IOs on node : bosserv8 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"wxyz\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=512K --iodepth=8  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1
    DEBUG: 2019/07/11 15:46:56 Successfully completed fio jobs on cluster nodes.
    DEBUG: 2019/07/11 15:46:56 Detaching volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:46:56 Detaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:47:00 Deleting volumes on the node : bosserv8
    DEBUG: 2019/07/11 15:47:00 Deleting volumes on the node : bosserv7
    DEBUG: 2019/07/11 15:48:18 

/******************************************** Stress Test Summary ***************************************************************************/
    DEBUG: 2019/07/11 15:48:18 /**** Completed Operations: Attach - Detach volumes in a loop. Total Iterations: 3 ****/
    DEBUG: 2019/07/11 15:48:18 /**** Completed Operations: Create - Attach - Write IO - Detach - Delete volumes in a loop. Total Iterations: 3 ****/
    DEBUG: 2019/07/11 15:48:18 /**** Completed Operation. Create - Attach - Write IO - Verify IO - Detach - Delete volumes in a loop. Total Iterations: 3 ****/
    DEBUG: 2019/07/11 15:48:18 
/*********************************************************************************************************************************************/


[AfterEach] create maximum mirrored volumes and run attach, IOs, detach delete in a loop
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:395
    DEBUG: 2019/07/11 15:48:18 END_TEST Mirroring.StressWithIO Time-taken : 2979.081284337

[32mâ€¢ [SLOW TEST:2979.081 seconds][0m
Mirroring.StressWithIO Weekly SM_Stress-1.6 SM_Stress-1.7 SM_Stress-1.9 SM_Stress-1.10
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:373[0m
  create maximum mirrored volumes and run attach, IOs, detach delete in a loop
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:381[0m
    creates maximum mirrored volumes and runs attach, IOs, detach delete in a loop
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:400[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mMirroring.RebootSourceNodeDuringResync Weekly SM_Reboot-2.13[0m [90mreboot the source node while resync is in progress and verify data is consistent across all plexes after reboot[0m 
  [1mreboot the source node while resync is in progress and verify data is consistent across all plexes after reboot[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:696[0m
[BeforeEach] reboot the source node while resync is in progress and verify data is consistent across all plexes after reboot
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:682
    DEBUG: 2019/07/11 15:48:18 START_TEST Mirroring.RebootSourceNodeDuringResync
    DEBUG: 2019/07/11 15:48:18 Login to cluster
    DEBUG: 2019/07/11 15:48:18 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 15:48:19 Checking basic Vnic usage
    DEBUG: 2019/07/11 15:48:19 Updating inventory struct
    DEBUG: 2019/07/11 15:48:25 Creating storage classes
[It] reboot the source node while resync is in progress and verify data is consistent across all plexes after reboot
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:696
    DEBUG: 2019/07/11 15:48:50 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2019/07/11 15:48:57 FBM and L1 usage is Zero across all nodes

    DEBUG: 2019/07/11 15:48:57 Assigning label to nodes where the plexes of mirrored volumes should get scheduled
    DEBUG: 2019/07/11 15:48:57 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 15:48:57 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 15:48:57 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 15:48:57 Creating 8 volumes of random sizes
    DEBUG: 2019/07/11 15:48:57 Mirror Count: 3
    DEBUG: 2019/07/11 15:49:06 Attaching all 8 volumes to node bosserv9
    DEBUG: 2019/07/11 15:49:40 Initiator node : bosserv9
    DEBUG: 2019/07/11 15:49:40 Nodes to reboot : bosserv8 bosserv7
    DEBUG: 2019/07/11 15:49:40 Node to reboot during Resync : bosserv9
    DEBUG: 2019/07/11 15:49:43 Running WRITE fio job on: bosserv9. FIO Command : echo -e '#!/bin/bash\n\nsudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --runtime=400 --blocksize=512K --iodepth=8  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 > /tmp/fio_result.txt & > /dev/null 2>&1' > /tmp/fio_run.sh

    DEBUG: 2019/07/11 15:49:46 Number of running fio process: 11

    DEBUG: 2019/07/11 15:53:06 Getting cluster quorum nodes
    DEBUG: 2019/07/11 15:53:06 Powering OFF the node bosserv8
    DEBUG: 2019/07/11 15:53:13 Node 172.16.230.16 took 6 seconds to power off
    DEBUG: 2019/07/11 15:53:13 Powering OFF the node bosserv7
    DEBUG: 2019/07/11 15:53:18 Node 172.16.230.14 took 5 seconds to power off
    DEBUG: 2019/07/11 15:53:18 Ensuring that bosserv8 node is unreachable: 
    DEBUG: 2019/07/11 15:53:18 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 15:53:27 Ensuring that bosserv7 node is unreachable: 
    DEBUG: 2019/07/11 15:53:27 Executing ping command: ping  -c 5 -W 5 bosserv7
    DEBUG: 2019/07/11 15:53:34 Powering ON the node bosserv8
    DEBUG: 2019/07/11 15:53:35 Node 172.16.230.16 took 1 seconds to power on
    DEBUG: 2019/07/11 15:53:35 Powering ON the node bosserv7
    DEBUG: 2019/07/11 15:53:37 Node 172.16.230.14 took 1 seconds to power on
    DEBUG: 2019/07/11 15:53:37 Checking if node bosserv8 is reachable or not: 
    DEBUG: 2019/07/11 15:53:37 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 15:53:54 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 15:54:11 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 15:54:28 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 15:54:45 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 15:54:49 bosserv8 is pingable from local machine
    DEBUG: 2019/07/11 15:54:49 Checking ssh port is up or not on node: bosserv8
    DEBUG: 2019/07/11 15:54:49 Checking if node bosserv7 is reachable or not: 
    DEBUG: 2019/07/11 15:54:49 Executing ping command: ping  -c 5 -W 5 bosserv7
    DEBUG: 2019/07/11 15:54:53 bosserv7 is pingable from local machine
    DEBUG: 2019/07/11 15:54:53 Checking ssh port is up or not on node: bosserv7
    DEBUG: 2019/07/11 15:55:23 Waiting for the node(s) to come up and rejoin the cluster
    DEBUG: 2019/07/11 15:55:26 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:29 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:32 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:32 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:32 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:32 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:32 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:32 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:32 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:33 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:34 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:35 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:36 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:37 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:38 Found '3' nodes
    DEBUG: 2019/07/11 15:55:38 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 15:55:43 Error: . Retrying once again...
    DEBUG: 2019/07/11 15:55:57 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 15:56:07 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 15:56:17 After power cycle/reboot, updating timestamp of node : bosserv8
    DEBUG: 2019/07/11 15:56:20 After power cycle/reboot, updating timestamp of node : bosserv7
    DEBUG: 2019/07/11 15:56:21 Getting cluster quorum nodes
    DEBUG: 2019/07/11 15:56:22 Updating timestamp of master, because cluster was not in quorum majority
    DEBUG: 2019/07/11 15:57:24 Updating inventory struct
    DEBUG: 2019/07/11 15:57:25 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2019/07/11 15:57:37 Nodes are up, waiting for armada to start
.
    DEBUG: 2019/07/11 15:58:47 Waiting for the nodes to go into Ready state
    DEBUG: 2019/07/11 15:58:47 Found '3' nodes
    DEBUG: 2019/07/11 15:58:47 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 15:58:47 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 15:58:47 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 15:58:47 Waiting for volumes to come into Attached state after rebooting cluster nodes.
    DEBUG: 2019/07/11 15:58:47 Volume "test-vol1" is in "Down" state. Waiting for it to come in "Attached" state.
    ERROR: 2019/07/11 16:07:07  util.go:212: TestFailed Timeout while waiting for test-vol1 state changing to Attached
    DEBUG: 2019/07/11 16:07:07 Collecting dw-techsupport log from all test nodes

    DEBUG: 2019/07/11 16:07:07 
Getting techsupport logs for all nodes
    DEBUG: 2019/07/11 16:07:07 Create techsupport log directory : 2019-07-11T16-07-07
    DEBUG: 2019/07/11 16:09:06 Getting tech support for 172.16.230.14 node, to directory 2019-07-11T16-07-07

    DEBUG: 2019/07/11 16:09:14 Getting tech support for 172.16.230.16 node, to directory 2019-07-11T16-07-07

    DEBUG: 2019/07/11 16:09:19 Getting tech support for 172.16.230.18 node, to directory 2019-07-11T16-07-07

    DEBUG: 2019/07/11 16:09:19 Creating pod log directory : pod_description_and_logs
    DEBUG: 2019/07/11 16:09:19 Collecting pod description and logs for all the pods ...
    DEBUG: 2019/07/11 16:09:31 Collected techsupport log location : /home/rajat/2019-07-11T16-07-07
    DEBUG: 2019/07/11 16:09:31 Copying e2e log file to directory : /home/rajat/2019-07-11T16-07-07
    DEBUG: 2019/07/11 16:09:31 Changing permissions of directory, so that all users can write to : 2019-07-11T16-07-07
[91mTestcase failed, refreshing testbed...[0m    DEBUG: 2019/07/11 16:09:31 Destroying the cluster
    DEBUG: 2019/07/11 16:09:31 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:32 Login to cluster
    DEBUG: 2019/07/11 16:09:32 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:33 Destroying the cluster: 5f378e34-a3ee-11e9-a1d7-a4bf01557f9f, Master node is bosserv8
    DEBUG: 2019/07/11 16:09:33 Checking in a loop for cluster status
    DEBUG: 2019/07/11 16:09:33 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:35 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:37 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:39 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:42 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:44 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:46 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:48 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:50 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:52 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:54 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:56 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:09:59 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:10:01 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:10:03 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:10:05 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:10:07 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:10:09 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:10:15 Doing sync all nodes.
    DEBUG: 2019/07/11 16:10:15 Doing sync all nodes.
    DEBUG: 2019/07/11 16:10:16 Doing sync all nodes.
    DEBUG: 2019/07/11 16:10:18 Checking for cluster-info.json on node :172.16.230.14
    DEBUG: 2019/07/11 16:10:19 Checking for cluster-info.json on node :172.16.230.16
    DEBUG: 2019/07/11 16:10:19 Checking for cluster-info.json on node :172.16.230.18
    DEBUG: 2019/07/11 16:10:19 Rebooting all nodes.
    DEBUG: 2019/07/11 16:10:19 Doing sync on 172.16.230.14
PolicyKit daemon disconnected from the bus.
We are no longer a registered authentication agent.
    DEBUG: 2019/07/11 16:10:21 Doing sync on 172.16.230.16
PolicyKit daemon disconnected from the bus.
We are no longer a registered authentication agent.
    DEBUG: 2019/07/11 16:10:21 Doing sync on 172.16.230.18
    DEBUG: 2019/07/11 16:10:22 Waiting for nodes to come up, will wait upto 800 seconds
.......    DEBUG: 2019/07/11 16:11:49 Nodes are up, waiting for armada to start
.....
[AfterEach] reboot the source node while resync is in progress and verify data is consistent across all plexes after reboot
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:691
    DEBUG: 2019/07/11 16:12:39 END_TEST Mirroring.RebootSourceNodeDuringResync Time-taken : 1460.577709062

[91m[1mâ€¢ Failure [1460.578 seconds][0m
Mirroring.RebootSourceNodeDuringResync Weekly SM_Reboot-2.13
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:675[0m
  reboot the source node while resync is in progress and verify data is consistent across all plexes after reboot
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:677[0m
    [91m[1mreboot the source node while resync is in progress and verify data is consistent across all plexes after reboot [It][0m
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:696[0m

    [91mFailure while waiting for volumes to come in "Attached" state. : Timeout while waiting for test-vol1 state changing to Attached
    Expected error:
        <*errors.errorString | 0xc420024350>: {
            s: "Timeout while waiting for test-vol1 state changing to Attached",
        }
        Timeout while waiting for test-vol1 state changing to Attached
    not to have occurred[0m

    /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/util.go:213
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mMirroring.LimitEightVolumesPerFioPod Weekly SM_Limit-1.2 Qos[0m [90mCreate fio pod with 8 mirrored volumes.[0m 
  [1mCreate fio pod with 8 mirrored volumes.[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:2752[0m
[BeforeEach] Create fio pod with 8 mirrored volumes.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:2737
    DEBUG: 2019/07/11 16:12:39 START_TEST Mirroring.LimitEightVolumesPerFioPod
    DEBUG: 2019/07/11 16:12:39 Cluster Spec Node list is [bosserv7 bosserv8 bosserv9]
    DEBUG: 2019/07/11 16:12:39 Getting dns domain name
    DEBUG: 2019/07/11 16:12:39 FQDN : bostontb3.bos.diamanti.com
    DEBUG: 2019/07/11 16:12:39 Generating certificates for the cluster: (Name: bostontb3, VIP: 172.16.230.103, FQDN: bostontb3.bos.diamanti.com)
    DEBUG: 2019/07/11 16:12:39 Clean up existing certs if any:
    DEBUG: 2019/07/11 16:12:39 Generate unique CA name with current date
    DEBUG: 2019/07/11 16:12:39 Integrate CA name in file
    DEBUG: 2019/07/11 16:12:39 Generate CA certs
    DEBUG: 2019/07/11 16:12:39 Create a CSR to generate a certificate using FQDN, VIP, Cluster Name for a server certs
    DEBUG: 2019/07/11 16:12:39 Generate server certificate:
    DEBUG: 2019/07/11 16:12:39 Getting CertificateAuthority from /home/rajat/diamanti-test-pkg/server_certs/ca.pem file
    DEBUG: 2019/07/11 16:12:39 Getting ServerCertificate from /home/rajat/diamanti-test-pkg/server_certs/server.pem file
    DEBUG: 2019/07/11 16:12:39 Getting ServerPrivateKey from /home/rajat/diamanti-test-pkg/server_certs/server-key.pem file
    DEBUG: 2019/07/11 16:12:39 Creating the cluster
    DEBUG: 2019/07/11 16:12:54 Please import "/home/rajat/diamanti-test-pkg/server_certs/ca.pem" certificate to your client machine
    DEBUG: 2019/07/11 16:12:54 Sleeping for 60 sec
    DEBUG: 2019/07/11 16:13:54 Login using 172.16.230.103 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:13:55 Login to cluster
    DEBUG: 2019/07/11 16:13:55 Polling for cluster login for 300 seconds.
    DEBUG: 2019/07/11 16:13:55 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:13:56 Checking in a loop for cluster status
    DEBUG: 2019/07/11 16:13:56 Found '3' nodes
    DEBUG: 2019/07/11 16:13:56 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 16:13:56 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 16:13:59 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 16:13:59 Creating network default
    DEBUG: 2019/07/11 16:13:59 Creating network blue
    DEBUG: 2019/07/11 16:13:59 Add default tag to default network
    DEBUG: 2019/07/11 16:14:10 Labeled all nodes with node=node$

    DEBUG: 2019/07/11 16:14:10 Getting cluster ID
    DEBUG: 2019/07/11 16:14:10 Created test cluster: 6389bd29-a431-11e9-aedd-a4bf01557f9f
    DEBUG: 2019/07/11 16:14:10 Deleting all LCVs, volumes, snapshots from previous cluster if any.
    DEBUG: 2019/07/11 16:14:32 Recording timestamp of all services on all nodes
    DEBUG: 2019/07/11 16:14:37 Overwritting e2e parameter : ExpectedBasicVnicUsageCount
    DEBUG: 2019/07/11 16:14:38 Checking if given pods are in Running state
    DEBUG: 2019/07/11 16:14:38 Checking if given pods are in Running state
    DEBUG: 2019/07/11 16:14:40 Checking if given pods are in Running state
    DEBUG: 2019/07/11 16:14:40 Checking if given pods are in Running state
    DEBUG: 2019/07/11 16:14:41 Updating inventory struct
    DEBUG: 2019/07/11 16:14:41 Creating storage classes
[It] Create fio pod with 8 mirrored volumes.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:2752
    DEBUG: 2019/07/11 16:15:02 Assigning label to nodes where the plexes of mirrored volumes should get scheduled
    DEBUG: 2019/07/11 16:15:02 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 16:15:02 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 16:15:02 Creating 8 Dynamic Persistent Volume Claims (PVCs). Mirror count: 2. Selector: 
    DEBUG: 2019/07/11 16:15:03 Created PVC successfully.
    DEBUG: 2019/07/11 16:15:03 Created PVC successfully.
    DEBUG: 2019/07/11 16:15:03 Created PVC successfully.
    DEBUG: 2019/07/11 16:15:03 Created PVC successfully.
    DEBUG: 2019/07/11 16:15:04 Created PVC successfully.
    DEBUG: 2019/07/11 16:15:04 Created PVC successfully.
    DEBUG: 2019/07/11 16:15:04 Created PVC successfully.
    DEBUG: 2019/07/11 16:15:04 Created PVC successfully.
    DEBUG: 2019/07/11 16:15:18 Creating 1 fio pods: 
    DEBUG: 2019/07/11 16:15:18 Checking if given pods are in Running state
    DEBUG: 2019/07/11 16:15:34 Wait for volumes to move into attached state: 
    DEBUG: 2019/07/11 16:15:34 Deleting pods : 
    DEBUG: 2019/07/11 16:15:40 Wait for volumes to come in Available state: 
    DEBUG: 2019/07/11 16:15:40 Volume "pvc-b8e2c9df-a431-11e9-9620-a4bf01557f9f" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2019/07/11 16:15:41 Volume "pvc-b909a4dc-a431-11e9-9620-a4bf01557f9f" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2019/07/11 16:15:42 Volume "pvc-b931f9f7-a431-11e9-9620-a4bf01557f9f" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2019/07/11 16:15:42 Volume "pvc-b952bbba-a431-11e9-9620-a4bf01557f9f" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2019/07/11 16:15:42 Volume "pvc-b974d600-a431-11e9-9620-a4bf01557f9f" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2019/07/11 16:15:42 Volume "pvc-b99ba891-a431-11e9-9620-a4bf01557f9f" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2019/07/11 16:15:42 Volume "pvc-b9c4d7d4-a431-11e9-9620-a4bf01557f9f" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2019/07/11 16:15:42 Volume "pvc-b9ed54ec-a431-11e9-9620-a4bf01557f9f" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2019/07/11 16:15:42 List PVCs: 
    DEBUG: 2019/07/11 16:15:42 Delete PVCs: 
    DEBUG: 2019/07/11 16:15:44 Waiting for volumes to get deleted: 
    DEBUG: 2019/07/11 16:16:30 Removing label from the nodes where the plexes of mirrored volumes were scheduled
    DEBUG: 2019/07/11 16:16:30 Removed label : mirror from node : bosserv7
    DEBUG: 2019/07/11 16:16:30 Removed label : mirror from node : bosserv8
[AfterEach] Create fio pod with 8 mirrored volumes.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:2747
    DEBUG: 2019/07/11 16:16:30 END_TEST Mirroring.LimitEightVolumesPerFioPod Time-taken : 231.363770496

[32mâ€¢ [SLOW TEST:231.364 seconds][0m
Mirroring.LimitEightVolumesPerFioPod Weekly SM_Limit-1.2 Qos
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:2729[0m
  Create fio pod with 8 mirrored volumes.
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:2730[0m
    Create fio pod with 8 mirrored volumes.
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:2752[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.PodWithMultipleVolsDo4KAndNon4KIOs Weekly RS_Verify-1.2[0m [90mFor same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously[0m 
  [1mFor same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4496[0m
[BeforeEach] For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4481
    DEBUG: 2019/07/11 16:16:30 START_TEST RemoteStorage.PodWithMultipleVolsDo4KAndNon4KIOs
    DEBUG: 2019/07/11 16:16:30 Login to cluster
    DEBUG: 2019/07/11 16:16:30 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:16:31 Checking basic Vnic usage
    DEBUG: 2019/07/11 16:16:31 Updating inventory struct
    DEBUG: 2019/07/11 16:16:37 Creating storage classes
[It] For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4496
    DEBUG: 2019/07/11 16:16:58 Create container specs for fio pod: 
    DEBUG: 2019/07/11 16:16:58 Create dynamic pvc: test-vol1
    DEBUG: 2019/07/11 16:16:58 Created PVC successfully.
    DEBUG: 2019/07/11 16:16:58 Create dynamic pvc: test-vol2
    DEBUG: 2019/07/11 16:16:58 Created PVC successfully.
    DEBUG: 2019/07/11 16:16:58 Fio pod with two remote volumes: 
    DEBUG: 2019/07/11 16:17:12 Sleeping for 180 sec so that prometheus will have some stats
    DEBUG: 2019/07/11 16:20:12 List PVCs: 
    DEBUG: 2019/07/11 16:20:12 Checking if IOs are happening: 
    DEBUG: 2019/07/11 16:20:12 Before deleting pod, check if it is in running state: 
    DEBUG: 2019/07/11 16:20:13 Delete pod: 
    DEBUG: 2019/07/11 16:20:15 Wait for volumes to come in "Available" state: 
    DEBUG: 2019/07/11 16:20:15 Volume "pvc-fdd3e4b1-a431-11e9-9620-a4bf01557f9f" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2019/07/11 16:20:16 Delete PVCs
    DEBUG: 2019/07/11 16:20:17 Waiting for volumes to get deleted: 
[AfterEach] For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4491
    DEBUG: 2019/07/11 16:21:00 END_TEST RemoteStorage.PodWithMultipleVolsDo4KAndNon4KIOs Time-taken : 270.089699269

[32mâ€¢ [SLOW TEST:270.090 seconds][0m
RemoteStorage.PodWithMultipleVolsDo4KAndNon4KIOs Weekly RS_Verify-1.2
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4470[0m
  For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4471[0m
    For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4496[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mMirroring.DetachTwoPlexesDuringIORebootTargetAfterAttach Weekly SM_PlexDetach-1.7[0m [90mdetaching two plexes during IO & attaching them during IO. Rebooting the target node. Verifying resync is successful[0m 
  [1mdetaches two plexes during IO & attaches them during IO. Rebooting the target node. Verifying resync is successful[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1458[0m
[BeforeEach] detaching two plexes during IO & attaching them during IO. Rebooting the target node. Verifying resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1444
    DEBUG: 2019/07/11 16:21:00 START_TEST Mirroring.DetachTwoPlexesDuringIORebootTargetAfterAttach
    DEBUG: 2019/07/11 16:21:00 Login to cluster
    DEBUG: 2019/07/11 16:21:00 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:21:01 Checking basic Vnic usage
    DEBUG: 2019/07/11 16:21:01 Updating inventory struct
    DEBUG: 2019/07/11 16:21:08 Creating storage classes
[It] detaches two plexes during IO & attaches them during IO. Rebooting the target node. Verifying resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1458
    DEBUG: 2019/07/11 16:21:29 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2019/07/11 16:21:35 FBM and L1 usage is Zero across all nodes

    DEBUG: 2019/07/11 16:21:35 Assigning label to nodes where the plexes of mirrored volumes should get scheduled
    DEBUG: 2019/07/11 16:21:35 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 16:21:35 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 16:21:35 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 16:21:35 Creating 8 volumes of random sizes
    DEBUG: 2019/07/11 16:21:35 Mirror Count: 3
    DEBUG: 2019/07/11 16:21:44 Attaching all 8 volumes to node bosserv8
    DEBUG: 2019/07/11 16:22:15 Running WRITE fio job on: bosserv8. FIO Command : echo -e '#!/bin/bash\n\nsudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --runtime=200 --blocksize=4K --iodepth=32  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 > /tmp/fio_result.txt & > /dev/null 2>&1' > /tmp/fio_run.sh

    DEBUG: 2019/07/11 16:22:18 Number of running fio process: 11

    DEBUG: 2019/07/11 16:23:18 Detaching first non initiator plex from all the volumes
    DEBUG: 2019/07/11 16:23:53 Detaching second non initiator plex from all the volumes
    DEBUG: 2019/07/11 16:24:17 Reattaching first non initiator plex to all the volumes
    DEBUG: 2019/07/11 16:24:33 Reattaching second non initiator plex to all the volumes
    DEBUG: 2019/07/11 16:24:34 Verifying if Resync of plexes has started
    DEBUG: 2019/07/11 16:24:34 Number of volumes : 8
    DEBUG: 2019/07/11 16:24:34 Checking resync progress on volume : test-vol8
    DEBUG: 2019/07/11 16:24:34 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:24:34 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:24:35 Volume "test-vol8" has index "7" in embedded.
    DEBUG: 2019/07/11 16:24:35 Volume: test-vol8. Resync offset: 7

    DEBUG: 2019/07/11 16:24:36 Volume: test-vol8. Resync offset: 10

    DEBUG: 2019/07/11 16:24:36 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:24:36 Checking resync progress on volume : test-vol4
    DEBUG: 2019/07/11 16:24:36 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:24:36 Volume name & Plex : test-vol4.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:24:37 Volume "test-vol4" has index "3" in embedded.
    DEBUG: 2019/07/11 16:24:38 Volume: test-vol4. Resync offset: 20

    DEBUG: 2019/07/11 16:24:38 Volume: test-vol4. Resync offset: 23

    DEBUG: 2019/07/11 16:24:38 Volume name & Plex : test-vol4.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:24:38 Checking resync progress on volume : test-vol1
    DEBUG: 2019/07/11 16:24:38 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:24:38 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:24:38 Volume name & Plex : test-vol1.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:24:39 Volume "test-vol1" has index "0" in embedded.
    DEBUG: 2019/07/11 16:24:40 Volume: test-vol1. Resync offset: 35

    DEBUG: 2019/07/11 16:24:40 Volume: test-vol1. Resync offset: 38

    DEBUG: 2019/07/11 16:24:40 Checking resync progress on volume : test-vol2
    DEBUG: 2019/07/11 16:24:40 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:24:40 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:24:40 Volume name & Plex : test-vol2.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:24:42 Volume "test-vol2" has index "1" in embedded.
    DEBUG: 2019/07/11 16:24:42 Volume: test-vol2. Resync offset: 46

    DEBUG: 2019/07/11 16:24:43 Volume: test-vol2. Resync offset: 50

    DEBUG: 2019/07/11 16:24:43 Checking resync progress on volume : test-vol3
    DEBUG: 2019/07/11 16:24:43 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:24:43 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:24:43 Volume name & Plex : test-vol3.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:24:44 Volume "test-vol3" has index "2" in embedded.
    DEBUG: 2019/07/11 16:24:44 Volume: test-vol3. Resync offset: 55

    DEBUG: 2019/07/11 16:24:45 Volume: test-vol3. Resync offset: 58

    DEBUG: 2019/07/11 16:24:45 Checking resync progress on volume : test-vol6
    DEBUG: 2019/07/11 16:24:45 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:24:45 Volume name & Plex : test-vol6.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:24:45 Volume name & Plex : test-vol6.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:24:46 Volume "test-vol6" has index "5" in embedded.
    DEBUG: 2019/07/11 16:24:47 Volume: test-vol6. Resync offset: 62

    DEBUG: 2019/07/11 16:24:47 Volume: test-vol6. Resync offset: 64

    DEBUG: 2019/07/11 16:24:47 Checking resync progress on volume : test-vol5
    DEBUG: 2019/07/11 16:24:47 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:24:47 Volume name & Plex : test-vol5.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:24:48 Volume "test-vol5" has index "4" in embedded.
    DEBUG: 2019/07/11 16:24:49 Volume: test-vol5. Resync offset: 77

    DEBUG: 2019/07/11 16:24:49 Volume: test-vol5. Resync offset: 80

    DEBUG: 2019/07/11 16:24:49 Volume name & Plex : test-vol5.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:24:49 Checking resync progress on volume : test-vol7
    DEBUG: 2019/07/11 16:24:50 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:24:50 Volume name & Plex : test-vol7.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:24:50 Volume name & Plex : test-vol7.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:24:51 Volume "test-vol7" has index "6" in embedded.
    DEBUG: 2019/07/11 16:24:51 Volume: test-vol7. Resync offset: 85

    DEBUG: 2019/07/11 16:24:52 Volume: test-vol7. Resync offset: 88

    DEBUG: 2019/07/11 16:24:52 Getting cluster quorum nodes
    DEBUG: 2019/07/11 16:24:52 Powering OFF the node bosserv9
    DEBUG: 2019/07/11 16:24:58 Node 172.16.230.18 took 6 seconds to power off
    DEBUG: 2019/07/11 16:24:58 Ensuring that bosserv9 node is unreachable: 
    DEBUG: 2019/07/11 16:24:58 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:25:07 Polling to check until node: bosserv9 goes down
    DEBUG: 2019/07/11 16:26:13 Powering ON the node bosserv9
    DEBUG: 2019/07/11 16:26:14 Node 172.16.230.18 took 1 seconds to power on
    DEBUG: 2019/07/11 16:26:14 Checking if node bosserv9 is reachable or not: 
    DEBUG: 2019/07/11 16:26:14 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:26:33 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:26:50 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:27:07 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:27:24 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:27:28 bosserv9 is pingable from local machine
    DEBUG: 2019/07/11 16:27:28 Checking ssh port is up or not on node: bosserv9
    DEBUG: 2019/07/11 16:27:58 Waiting for the node(s) to come up and rejoin the cluster
    DEBUG: 2019/07/11 16:27:58 Found '3' nodes
    DEBUG: 2019/07/11 16:27:58 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 16:27:58 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 16:27:58 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 16:28:41 After power cycle/reboot, updating timestamp of node : bosserv9
    DEBUG: 2019/07/11 16:28:43 Getting cluster quorum nodes
    DEBUG: 2019/07/11 16:29:43 Updating inventory struct
    DEBUG: 2019/07/11 16:29:43 Comparing Volume's UUID with nvme id-ns for all volumes
    DEBUG: 2019/07/11 16:29:47 Waiting for fio job to complete on the node
    DEBUG: 2019/07/11 16:29:47 Verifying if Resync of plexes has completed
    DEBUG: 2019/07/11 16:29:47 Number of volumes : 8
    DEBUG: 2019/07/11 16:29:47 Checking resync progress on volume : test-vol8
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 All plexes of volume "test-vol8" are in "InUse" state.
    DEBUG: 2019/07/11 16:29:47 Checking resync progress on volume : test-vol4
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol4.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol4.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 All plexes of volume "test-vol4" are in "InUse" state.
    DEBUG: 2019/07/11 16:29:47 Checking resync progress on volume : test-vol1
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol1.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 All plexes of volume "test-vol1" are in "InUse" state.
    DEBUG: 2019/07/11 16:29:47 Checking resync progress on volume : test-vol2
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol2.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 All plexes of volume "test-vol2" are in "InUse" state.
    DEBUG: 2019/07/11 16:29:47 Checking resync progress on volume : test-vol3
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol3.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 All plexes of volume "test-vol3" are in "InUse" state.
    DEBUG: 2019/07/11 16:29:47 Checking resync progress on volume : test-vol6
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol6.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 Volume name & Plex : test-vol6.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:29:47 All plexes of volume "test-vol6" are in "InUse" state.
    DEBUG: 2019/07/11 16:29:47 Checking resync progress on volume : test-vol5
    DEBUG: 2019/07/11 16:29:48 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:29:48 Volume name & Plex : test-vol5.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:29:48 Volume name & Plex : test-vol5.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:29:48 All plexes of volume "test-vol5" are in "InUse" state.
    DEBUG: 2019/07/11 16:29:48 Checking resync progress on volume : test-vol7
    DEBUG: 2019/07/11 16:29:48 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:29:48 Volume name & Plex : test-vol7.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:29:48 Volume name & Plex : test-vol7.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:29:48 All plexes of volume "test-vol7" are in "InUse" state.
    DEBUG: 2019/07/11 16:29:51 Verifying sha512sum across all plexes
    DEBUG: 2019/07/11 16:29:52 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 16:29:53 Changing preferred plex of volume: test-vol2. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 16:29:54 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 16:29:55 Changing preferred plex of volume: test-vol4. Volume load index: 3.New preferred plex: 0
    DEBUG: 2019/07/11 16:29:56 Changing preferred plex of volume: test-vol5. Volume load index: 4.New preferred plex: 0
    DEBUG: 2019/07/11 16:29:57 Changing preferred plex of volume: test-vol6. Volume load index: 5.New preferred plex: 0
    DEBUG: 2019/07/11 16:29:58 Changing preferred plex of volume: test-vol7. Volume load index: 6.New preferred plex: 0
    DEBUG: 2019/07/11 16:29:59 Changing preferred plex of volume: test-vol8. Volume load index: 7.New preferred plex: 0
    DEBUG: 2019/07/11 16:30:00 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2019/07/11 16:30:00 Calculating cksum for volume test-vol2 and plex p0
    DEBUG: 2019/07/11 16:30:00 Calculating cksum for volume test-vol3 and plex p0
    DEBUG: 2019/07/11 16:30:00 Calculating cksum for volume test-vol4 and plex p0
    DEBUG: 2019/07/11 16:30:00 Calculating cksum for volume test-vol5 and plex p0
    DEBUG: 2019/07/11 16:30:00 Calculating cksum for volume test-vol6 and plex p0
    DEBUG: 2019/07/11 16:30:00 Calculating cksum for volume test-vol7 and plex p0
    DEBUG: 2019/07/11 16:30:00 Calculating cksum for volume test-vol8 and plex p0
    DEBUG: 2019/07/11 16:30:06 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 16:30:07 Changing preferred plex of volume: test-vol2. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 16:30:08 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 16:30:09 Changing preferred plex of volume: test-vol4. Volume load index: 3.New preferred plex: 1
    DEBUG: 2019/07/11 16:30:10 Changing preferred plex of volume: test-vol5. Volume load index: 4.New preferred plex: 1
    DEBUG: 2019/07/11 16:30:11 Changing preferred plex of volume: test-vol6. Volume load index: 5.New preferred plex: 1
    DEBUG: 2019/07/11 16:30:12 Changing preferred plex of volume: test-vol7. Volume load index: 6.New preferred plex: 1
    DEBUG: 2019/07/11 16:30:13 Changing preferred plex of volume: test-vol8. Volume load index: 7.New preferred plex: 1
    DEBUG: 2019/07/11 16:30:14 Calculating cksum for volume test-vol1 and plex p1
    DEBUG: 2019/07/11 16:30:14 Calculating cksum for volume test-vol2 and plex p1
    DEBUG: 2019/07/11 16:30:14 Calculating cksum for volume test-vol3 and plex p1
    DEBUG: 2019/07/11 16:30:14 Calculating cksum for volume test-vol4 and plex p1
    DEBUG: 2019/07/11 16:30:14 Calculating cksum for volume test-vol5 and plex p1
    DEBUG: 2019/07/11 16:30:14 Calculating cksum for volume test-vol6 and plex p1
    DEBUG: 2019/07/11 16:30:14 Calculating cksum for volume test-vol7 and plex p1
    DEBUG: 2019/07/11 16:30:14 Calculating cksum for volume test-vol8 and plex p1
    DEBUG: 2019/07/11 16:30:20 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 16:30:21 Changing preferred plex of volume: test-vol2. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 16:30:22 Changing preferred plex of volume: test-vol3. Volume load index: 2.New preferred plex: 2
    DEBUG: 2019/07/11 16:30:23 Changing preferred plex of volume: test-vol4. Volume load index: 3.New preferred plex: 2
    DEBUG: 2019/07/11 16:30:24 Changing preferred plex of volume: test-vol5. Volume load index: 4.New preferred plex: 2
    DEBUG: 2019/07/11 16:30:25 Changing preferred plex of volume: test-vol6. Volume load index: 5.New preferred plex: 2
    DEBUG: 2019/07/11 16:30:26 Changing preferred plex of volume: test-vol7. Volume load index: 6.New preferred plex: 2
    DEBUG: 2019/07/11 16:30:27 Changing preferred plex of volume: test-vol8. Volume load index: 7.New preferred plex: 2
    DEBUG: 2019/07/11 16:30:28 Calculating cksum for volume test-vol1 and plex p2
    DEBUG: 2019/07/11 16:30:28 Calculating cksum for volume test-vol2 and plex p2
    DEBUG: 2019/07/11 16:30:28 Calculating cksum for volume test-vol3 and plex p2
    DEBUG: 2019/07/11 16:30:28 Calculating cksum for volume test-vol4 and plex p2
    DEBUG: 2019/07/11 16:30:28 Calculating cksum for volume test-vol5 and plex p2
    DEBUG: 2019/07/11 16:30:28 Calculating cksum for volume test-vol6 and plex p2
    DEBUG: 2019/07/11 16:30:28 Calculating cksum for volume test-vol7 and plex p2
    DEBUG: 2019/07/11 16:30:28 Calculating cksum for volume test-vol8 and plex p2
    DEBUG: 2019/07/11 16:30:32 Sha512sum matched for all volumes across all plexes
    DEBUG: 2019/07/11 16:30:32 Detach & Delete all volumes
    DEBUG: 2019/07/11 16:31:30 Removing label from the nodes where the plexes of mirrored volumes were scheduled
    DEBUG: 2019/07/11 16:31:30 Removed label : mirror from node : bosserv9
    DEBUG: 2019/07/11 16:31:31 Removed label : mirror from node : bosserv8
    DEBUG: 2019/07/11 16:31:31 Removed label : mirror from node : bosserv7
[AfterEach] detaching two plexes during IO & attaching them during IO. Rebooting the target node. Verifying resync is successful
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1453
    DEBUG: 2019/07/11 16:31:31 END_TEST Mirroring.DetachTwoPlexesDuringIORebootTargetAfterAttach Time-taken : 630.59335952

[32mâ€¢ [SLOW TEST:630.593 seconds][0m
Mirroring.DetachTwoPlexesDuringIORebootTargetAfterAttach Weekly SM_PlexDetach-1.7
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1437[0m
  detaching two plexes during IO & attaching them during IO. Rebooting the target node. Verifying resync is successful
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1439[0m
    detaches two plexes during IO & attaches them during IO. Rebooting the target node. Verifying resync is successful
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1458[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mMirroring.ResyncAllNodeReboot Weekly SM_Reboot-2.12[0m [90mreboot all the nodes while IO is in progress and verify data is consistent across all plexes after reboot[0m 
  [1mreboot all the nodes while IO is in progress and verify data is consistent across all plexes after reboot[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:649[0m
[BeforeEach] reboot all the nodes while IO is in progress and verify data is consistent across all plexes after reboot
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:635
    DEBUG: 2019/07/11 16:31:31 START_TEST Mirroring.ResyncAllNodeReboot
    DEBUG: 2019/07/11 16:31:31 Login to cluster
    DEBUG: 2019/07/11 16:31:31 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:31:32 Checking basic Vnic usage
    DEBUG: 2019/07/11 16:31:32 Updating inventory struct
    DEBUG: 2019/07/11 16:31:38 Creating storage classes
[It] reboot all the nodes while IO is in progress and verify data is consistent across all plexes after reboot
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:649
    DEBUG: 2019/07/11 16:31:59 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2019/07/11 16:32:06 FBM and L1 usage is Zero across all nodes

    DEBUG: 2019/07/11 16:32:06 Assigning label to nodes where the plexes of mirrored volumes should get scheduled
    DEBUG: 2019/07/11 16:32:06 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 16:32:06 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 16:32:06 Creating 8 volumes of random sizes
    DEBUG: 2019/07/11 16:32:06 Mirror Count: 2
    DEBUG: 2019/07/11 16:32:15 Attaching all 8 volumes to node bosserv9
    DEBUG: 2019/07/11 16:32:45 Initiator node : bosserv9
    DEBUG: 2019/07/11 16:32:45 Nodes to reboot : bosserv9 bosserv8
    DEBUG: 2019/07/11 16:32:48 Running WRITE fio job on: bosserv9. FIO Command : echo -e '#!/bin/bash\n\nsudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096 --runtime=400 --blocksize=512K --iodepth=8  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 > /tmp/fio_result.txt & > /dev/null 2>&1' > /tmp/fio_run.sh

    DEBUG: 2019/07/11 16:32:51 Number of running fio process: 11

    DEBUG: 2019/07/11 16:36:11 Getting cluster quorum nodes
    DEBUG: 2019/07/11 16:36:11 Powering OFF the node bosserv9
    DEBUG: 2019/07/11 16:36:18 Node 172.16.230.18 took 6 seconds to power off
    DEBUG: 2019/07/11 16:36:18 Powering OFF the node bosserv8
    DEBUG: 2019/07/11 16:36:24 Node 172.16.230.16 took 6 seconds to power off
    DEBUG: 2019/07/11 16:36:24 Ensuring that bosserv9 node is unreachable: 
    DEBUG: 2019/07/11 16:36:24 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:36:33 Ensuring that bosserv8 node is unreachable: 
    DEBUG: 2019/07/11 16:36:33 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 16:36:43 Powering ON the node bosserv9
    DEBUG: 2019/07/11 16:36:44 Node 172.16.230.18 took 1 seconds to power on
    DEBUG: 2019/07/11 16:36:44 Powering ON the node bosserv8
    DEBUG: 2019/07/11 16:36:45 Node 172.16.230.16 took 1 seconds to power on
    DEBUG: 2019/07/11 16:36:45 Checking if node bosserv9 is reachable or not: 
    DEBUG: 2019/07/11 16:36:45 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:37:04 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:37:21 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:37:38 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:37:55 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 16:37:59 bosserv9 is pingable from local machine
    DEBUG: 2019/07/11 16:37:59 Checking ssh port is up or not on node: bosserv9
    DEBUG: 2019/07/11 16:37:59 Checking if node bosserv8 is reachable or not: 
    DEBUG: 2019/07/11 16:37:59 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 16:38:03 bosserv8 is pingable from local machine
    DEBUG: 2019/07/11 16:38:03 Checking ssh port is up or not on node: bosserv8
    DEBUG: 2019/07/11 16:38:33 Waiting for the node(s) to come up and rejoin the cluster
    DEBUG: 2019/07/11 16:38:39 Found '3' nodes
    DEBUG: 2019/07/11 16:38:39 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 16:38:39 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:09 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:10 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:12 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:13 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:18 Error: . Retrying once again...
    DEBUG: 2019/07/11 16:39:23 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 16:39:33 After power cycle/reboot, updating timestamp of node : bosserv9
    DEBUG: 2019/07/11 16:39:35 After power cycle/reboot, updating timestamp of node : bosserv8
    DEBUG: 2019/07/11 16:39:37 Getting cluster quorum nodes
    DEBUG: 2019/07/11 16:39:37 Updating timestamp of master, because cluster was not in quorum majority
    DEBUG: 2019/07/11 16:40:40 Updating inventory struct
    DEBUG: 2019/07/11 16:40:40 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2019/07/11 16:40:52 Nodes are up, waiting for armada to start
.
    DEBUG: 2019/07/11 16:42:02 Waiting for the nodes to go into Ready state
    DEBUG: 2019/07/11 16:42:02 Found '3' nodes
    DEBUG: 2019/07/11 16:42:02 Waitting for bosserv7 to into "Ready" state.
    DEBUG: 2019/07/11 16:42:02 Waitting for bosserv8 to into "Ready" state.
    DEBUG: 2019/07/11 16:42:02 Waitting for bosserv9 to into "Ready" state.
    DEBUG: 2019/07/11 16:42:02 Waiting for volumes to come into Attached state after rebooting cluster nodes.
    DEBUG: 2019/07/11 16:42:05 Comparing Volume's UUID with nvme id-ns for all volumes
    DEBUG: 2019/07/11 16:42:08 Comparing the device path & uuid on initiator before and after target reboot
    DEBUG: 2019/07/11 16:42:09 Number of volumes : 8
    DEBUG: 2019/07/11 16:42:09 Checking resync progress on volume : test-vol8
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 All plexes of volume "test-vol8" are in "InUse" state.
    DEBUG: 2019/07/11 16:42:09 Checking resync progress on volume : test-vol4
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol4.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 All plexes of volume "test-vol4" are in "InUse" state.
    DEBUG: 2019/07/11 16:42:09 Checking resync progress on volume : test-vol1
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 All plexes of volume "test-vol1" are in "InUse" state.
    DEBUG: 2019/07/11 16:42:09 Checking resync progress on volume : test-vol2
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 All plexes of volume "test-vol2" are in "InUse" state.
    DEBUG: 2019/07/11 16:42:09 Checking resync progress on volume : test-vol3
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 All plexes of volume "test-vol3" are in "InUse" state.
    DEBUG: 2019/07/11 16:42:09 Checking resync progress on volume : test-vol6
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol6.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 All plexes of volume "test-vol6" are in "InUse" state.
    DEBUG: 2019/07/11 16:42:09 Checking resync progress on volume : test-vol5
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol5.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 All plexes of volume "test-vol5" are in "InUse" state.
    DEBUG: 2019/07/11 16:42:09 Checking resync progress on volume : test-vol7
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 Volume name & Plex : test-vol7.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:42:09 All plexes of volume "test-vol7" are in "InUse" state.
    DEBUG: 2019/07/11 16:42:13 Changing preferred plex of volume: test-vol1. Volume load index: 3.New preferred plex: 0
    DEBUG: 2019/07/11 16:42:14 Changing preferred plex of volume: test-vol2. Volume load index: 4.New preferred plex: 0
    DEBUG: 2019/07/11 16:42:15 Changing preferred plex of volume: test-vol3. Volume load index: 5.New preferred plex: 0
    DEBUG: 2019/07/11 16:42:17 Changing preferred plex of volume: test-vol4. Volume load index: 6.New preferred plex: 0
    DEBUG: 2019/07/11 16:42:18 Changing preferred plex of volume: test-vol5. Volume load index: 7.New preferred plex: 0
    DEBUG: 2019/07/11 16:42:19 Changing preferred plex of volume: test-vol6. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 16:42:20 Changing preferred plex of volume: test-vol7. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 16:42:21 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 16:42:22 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2019/07/11 16:42:22 Calculating cksum for volume test-vol2 and plex p0
    DEBUG: 2019/07/11 16:42:22 Calculating cksum for volume test-vol3 and plex p0
    DEBUG: 2019/07/11 16:42:22 Calculating cksum for volume test-vol4 and plex p0
    DEBUG: 2019/07/11 16:42:22 Calculating cksum for volume test-vol5 and plex p0
    DEBUG: 2019/07/11 16:42:22 Calculating cksum for volume test-vol6 and plex p0
    DEBUG: 2019/07/11 16:42:22 Calculating cksum for volume test-vol7 and plex p0
    DEBUG: 2019/07/11 16:42:22 Calculating cksum for volume test-vol8 and plex p0
    DEBUG: 2019/07/11 16:44:52 Changing preferred plex of volume: test-vol1. Volume load index: 3.New preferred plex: 1
    DEBUG: 2019/07/11 16:44:53 Changing preferred plex of volume: test-vol2. Volume load index: 4.New preferred plex: 1
    DEBUG: 2019/07/11 16:44:54 Changing preferred plex of volume: test-vol3. Volume load index: 5.New preferred plex: 1
    DEBUG: 2019/07/11 16:44:55 Changing preferred plex of volume: test-vol4. Volume load index: 6.New preferred plex: 1
    DEBUG: 2019/07/11 16:44:56 Changing preferred plex of volume: test-vol5. Volume load index: 7.New preferred plex: 1
    DEBUG: 2019/07/11 16:44:57 Changing preferred plex of volume: test-vol6. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 16:44:59 Changing preferred plex of volume: test-vol7. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 16:45:00 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 16:45:00 Calculating cksum for volume test-vol1 and plex p1
    DEBUG: 2019/07/11 16:45:00 Calculating cksum for volume test-vol2 and plex p1
    DEBUG: 2019/07/11 16:45:01 Calculating cksum for volume test-vol3 and plex p1
    DEBUG: 2019/07/11 16:45:01 Calculating cksum for volume test-vol4 and plex p1
    DEBUG: 2019/07/11 16:45:01 Calculating cksum for volume test-vol5 and plex p1
    DEBUG: 2019/07/11 16:45:01 Calculating cksum for volume test-vol6 and plex p1
    DEBUG: 2019/07/11 16:45:01 Calculating cksum for volume test-vol7 and plex p1
    DEBUG: 2019/07/11 16:45:01 Calculating cksum for volume test-vol8 and plex p1
    DEBUG: 2019/07/11 16:47:44 Successfully completed Verification on all the plexes
    DEBUG: 2019/07/11 16:47:44 Detach & Delete all volumes
    DEBUG: 2019/07/11 16:49:15 Removing label from the nodes where the plexes of mirrored volumes were scheduled
    DEBUG: 2019/07/11 16:49:15 Removed label : mirror from node : bosserv9
    DEBUG: 2019/07/11 16:49:15 Removed label : mirror from node : bosserv8
[AfterEach] reboot all the nodes while IO is in progress and verify data is consistent across all plexes after reboot
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:644
    DEBUG: 2019/07/11 16:49:15 END_TEST Mirroring.ResyncAllNodeReboot Time-taken : 1064.49753705

[32mâ€¢ [SLOW TEST:1064.498 seconds][0m
Mirroring.ResyncAllNodeReboot Weekly SM_Reboot-2.12
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:628[0m
  reboot all the nodes while IO is in progress and verify data is consistent across all plexes after reboot
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:630[0m
    reboot all the nodes while IO is in progress and verify data is consistent across all plexes after reboot
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:649[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0mMirroring.OnlinePlexAddWhileOtherPlexIsResyncing Weekly SM_PlexAdd-1.2[0m [90mCreate simple volumes, do IOs, add plex. While the plex starts resyncing, add another plex. Validate data on each plex of each volume.[0m 
  [1mCreate simple volumes, do IOs, add plex. While the plex starts resyncing, add another plex. Validate data on each plex of each volume.[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1987[0m
[BeforeEach] Create simple volumes, do IOs, add plex. While the plex starts resyncing, add another plex. Validate data on each plex of each volume.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1972
    DEBUG: 2019/07/11 16:49:15 START_TEST Mirroring.OnlinePlexAddWhileOtherPlexIsResyncing
    DEBUG: 2019/07/11 16:49:15 Login to cluster
    DEBUG: 2019/07/11 16:49:15 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 16:49:16 Checking basic Vnic usage
    DEBUG: 2019/07/11 16:49:16 Updating inventory struct
    DEBUG: 2019/07/11 16:49:22 Creating storage classes
[It] Create simple volumes, do IOs, add plex. While the plex starts resyncing, add another plex. Validate data on each plex of each volume.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1987
    DEBUG: 2019/07/11 16:49:40 Creating 8 volumes. Mirror Count: 1:
    DEBUG: 2019/07/11 16:49:40 Mirror Count: 1
    DEBUG: 2019/07/11 16:49:48 Attaching volumes: 
    DEBUG: 2019/07/11 16:50:18 Running write fio job on all volumes: 
    DEBUG: 2019/07/11 16:50:18 Running Write IOs on node : bosserv8 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=120 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 16:50:18 Running Write IOs on node : bosserv7 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=120 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 16:50:18 Running Write IOs on node : bosserv9 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=120 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 16:52:19 Adding new plex to each simple volumes. Expected PlexCount 2: 
    DEBUG: 2019/07/11 16:52:20 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:20 Volume name & Plex : test-vol1.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:22 Volume "test-vol1" has index "0" in embedded.
    DEBUG: 2019/07/11 16:52:22 Volume: test-vol1. Resync offset: 66

    DEBUG: 2019/07/11 16:52:23 Volume: test-vol1. Resync offset: 79

    DEBUG: 2019/07/11 16:52:23 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:23 Volume name & Plex : test-vol2.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:24 Volume "test-vol2" has index "0" in embedded.
    DEBUG: 2019/07/11 16:52:24 Volume: test-vol2. Resync offset: 15

    DEBUG: 2019/07/11 16:52:25 Volume: test-vol2. Resync offset: 17

    DEBUG: 2019/07/11 16:52:25 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:25 Volume name & Plex : test-vol3.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:26 Volume "test-vol3" has index "0" in embedded.
    DEBUG: 2019/07/11 16:52:27 Volume: test-vol3. Resync offset: 14

    DEBUG: 2019/07/11 16:52:27 Volume: test-vol3. Resync offset: 15

    DEBUG: 2019/07/11 16:52:27 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:27 Volume name & Plex : test-vol4.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:28 Volume "test-vol4" has index "1" in embedded.
    DEBUG: 2019/07/11 16:52:29 Volume: test-vol4. Resync offset: 13

    DEBUG: 2019/07/11 16:52:30 Volume: test-vol4. Resync offset: 14

    DEBUG: 2019/07/11 16:52:30 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:30 Volume name & Plex : test-vol5.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:31 Volume "test-vol5" has index "1" in embedded.
    DEBUG: 2019/07/11 16:52:31 Volume: test-vol5. Resync offset: 13

    DEBUG: 2019/07/11 16:52:32 Volume: test-vol5. Resync offset: 13

    DEBUG: 2019/07/11 16:52:38 Volume: test-vol5. Resync offset: 21

    DEBUG: 2019/07/11 16:52:38 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:38 Volume name & Plex : test-vol6.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:39 Volume "test-vol6" has index "1" in embedded.
    DEBUG: 2019/07/11 16:52:39 Volume: test-vol6. Resync offset: 19

    DEBUG: 2019/07/11 16:52:40 Volume: test-vol6. Resync offset: 20

    DEBUG: 2019/07/11 16:52:40 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:40 Volume name & Plex : test-vol7.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:41 Volume "test-vol7" has index "2" in embedded.
    DEBUG: 2019/07/11 16:52:42 Volume: test-vol7. Resync offset: 19

    DEBUG: 2019/07/11 16:52:42 Volume: test-vol7. Resync offset: 20

    DEBUG: 2019/07/11 16:52:42 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:42 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:43 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 16:52:44 Volume: test-vol8. Resync offset: 18

    DEBUG: 2019/07/11 16:52:45 Volume: test-vol8. Resync offset: 19

    DEBUG: 2019/07/11 16:52:45 Adding new plex to each simple volumes. Expected PlexCount 3: 
    DEBUG: 2019/07/11 16:52:46 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:46 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:52:46 Volume name & Plex : test-vol1.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:47 Volume "test-vol1" has index "0" in embedded.
    DEBUG: 2019/07/11 16:52:48 Volume: test-vol1. Resync offset: 63

    DEBUG: 2019/07/11 16:52:48 Volume: test-vol1. Resync offset: 76

    DEBUG: 2019/07/11 16:52:48 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:48 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:52:48 Volume name & Plex : test-vol2.p2. Plex State : Detached
    DEBUG: 2019/07/11 16:52:50 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:50 Volume name & Plex : test-vol3.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:52 Volume "test-vol3" has index "0" in embedded.
    DEBUG: 2019/07/11 16:52:52 Volume: test-vol3. Resync offset: 69

    DEBUG: 2019/07/11 16:52:53 Volume: test-vol3. Resync offset: 70

    DEBUG: 2019/07/11 16:52:53 Volume name & Plex : test-vol3.p2. Plex State : 
    DEBUG: 2019/07/11 16:52:53 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:53 Volume name & Plex : test-vol4.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:54 Volume "test-vol4" has index "1" in embedded.
    DEBUG: 2019/07/11 16:52:54 Volume: test-vol4. Resync offset: 53

    DEBUG: 2019/07/11 16:52:55 Volume: test-vol4. Resync offset: 54

    DEBUG: 2019/07/11 16:52:55 Volume name & Plex : test-vol4.p2. Plex State : 
    DEBUG: 2019/07/11 16:52:55 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:52:55 Volume name & Plex : test-vol5.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:52:56 Volume "test-vol5" has index "1" in embedded.
    DEBUG: 2019/07/11 16:52:57 Volume: test-vol5. Resync offset: 42

    DEBUG: 2019/07/11 16:52:57 Volume: test-vol5. Resync offset: 42

    DEBUG: 2019/07/11 16:53:03 Volume: test-vol5. Resync offset: 49

    DEBUG: 2019/07/11 16:53:03 Volume name & Plex : test-vol5.p2. Plex State : 
    DEBUG: 2019/07/11 16:53:03 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:53:03 Volume name & Plex : test-vol6.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:53:04 Volume "test-vol6" has index "1" in embedded.
    DEBUG: 2019/07/11 16:53:04 Volume: test-vol6. Resync offset: 47

    DEBUG: 2019/07/11 16:53:05 Volume: test-vol6. Resync offset: 47

    DEBUG: 2019/07/11 16:53:11 Volume: test-vol6. Resync offset: 54

    DEBUG: 2019/07/11 16:53:11 Volume name & Plex : test-vol6.p2. Plex State : 
    DEBUG: 2019/07/11 16:53:11 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:53:11 Volume name & Plex : test-vol7.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:53:12 Volume "test-vol7" has index "2" in embedded.
    DEBUG: 2019/07/11 16:53:12 Volume: test-vol7. Resync offset: 48

    DEBUG: 2019/07/11 16:53:13 Volume: test-vol7. Resync offset: 49

    DEBUG: 2019/07/11 16:53:13 Volume name & Plex : test-vol7.p2. Plex State : 
    DEBUG: 2019/07/11 16:53:13 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:53:13 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:53:14 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 16:53:15 Volume: test-vol8. Resync offset: 42

    DEBUG: 2019/07/11 16:53:15 Volume: test-vol8. Resync offset: 43

    DEBUG: 2019/07/11 16:53:15 Volume name & Plex : test-vol8.p2. Plex State : 
    DEBUG: 2019/07/11 16:53:15 Wait till resync completion on all volumes
    DEBUG: 2019/07/11 16:53:15 Number of volumes : 8
    DEBUG: 2019/07/11 16:53:15 Checking resync progress on volume : test-vol8
    DEBUG: 2019/07/11 16:53:15 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:53:15 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:53:16 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 16:53:17 Volume: test-vol8. Resync offset: 44

    DEBUG: 2019/07/11 16:53:18 Volume: test-vol8. Resync offset: 44

    DEBUG: 2019/07/11 16:53:23 Volume: test-vol8. Resync offset: 49

    DEBUG: 2019/07/11 16:53:23 Volume name & Plex : test-vol8.p2. Plex State : 
    DEBUG: 2019/07/11 16:53:23 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 16:53:53 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:53:53 Volume name & Plex : test-vol8.p1. Plex State : Resyncing
    DEBUG: 2019/07/11 16:53:54 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 16:53:55 Volume: test-vol8. Resync offset: 77

    DEBUG: 2019/07/11 16:53:56 Volume: test-vol8. Resync offset: 78

    DEBUG: 2019/07/11 16:53:56 Volume name & Plex : test-vol8.p2. Plex State : 
    DEBUG: 2019/07/11 16:53:56 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 16:54:26 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:54:26 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:54:26 Volume name & Plex : test-vol8.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:54:27 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 16:54:27 Volume: test-vol8. Resync offset: 6

    DEBUG: 2019/07/11 16:54:28 Volume: test-vol8. Resync offset: 6

    DEBUG: 2019/07/11 16:54:34 Volume: test-vol8. Resync offset: 11

    DEBUG: 2019/07/11 16:54:34 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 16:55:04 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:55:04 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:55:04 Volume name & Plex : test-vol8.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:55:05 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 16:55:05 Volume: test-vol8. Resync offset: 39

    DEBUG: 2019/07/11 16:55:06 Volume: test-vol8. Resync offset: 40

    DEBUG: 2019/07/11 16:55:06 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 16:55:36 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:55:36 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:55:36 Volume name & Plex : test-vol8.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:55:37 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 16:55:38 Volume: test-vol8. Resync offset: 67

    DEBUG: 2019/07/11 16:55:38 Volume: test-vol8. Resync offset: 68

    DEBUG: 2019/07/11 16:55:38 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 16:56:08 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:56:08 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:56:08 Volume name & Plex : test-vol8.p2. Plex State : Resyncing
    DEBUG: 2019/07/11 16:56:09 Volume "test-vol8" has index "2" in embedded.
    DEBUG: 2019/07/11 16:56:10 Volume: test-vol8. Resync offset: 94

    DEBUG: 2019/07/11 16:56:11 Volume: test-vol8. Resync offset: 94

    DEBUG: 2019/07/11 16:56:16 Volume: test-vol8. Resync offset: 99

    DEBUG: 2019/07/11 16:56:16 Resync yet to complete. Sleeping for 30 seconds before checking resync progress.
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol8.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol8.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol8.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 All plexes of volume "test-vol8" are in "InUse" state.
    DEBUG: 2019/07/11 16:56:46 Checking resync progress on volume : test-vol4
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol4.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol4.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol4.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 All plexes of volume "test-vol4" are in "InUse" state.
    DEBUG: 2019/07/11 16:56:46 Checking resync progress on volume : test-vol1
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol1.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol1.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol1.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 All plexes of volume "test-vol1" are in "InUse" state.
    DEBUG: 2019/07/11 16:56:46 Checking resync progress on volume : test-vol2
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol2.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol2.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 Volume name & Plex : test-vol2.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:56:46 All plexes of volume "test-vol2" are in "InUse" state.
    DEBUG: 2019/07/11 16:56:46 Checking resync progress on volume : test-vol6
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol6.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol6.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol6.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 All plexes of volume "test-vol6" are in "InUse" state.
    DEBUG: 2019/07/11 16:56:47 Checking resync progress on volume : test-vol3
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol3.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol3.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol3.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 All plexes of volume "test-vol3" are in "InUse" state.
    DEBUG: 2019/07/11 16:56:47 Checking resync progress on volume : test-vol7
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol7.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol7.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol7.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 All plexes of volume "test-vol7" are in "InUse" state.
    DEBUG: 2019/07/11 16:56:47 Checking resync progress on volume : test-vol5
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol5.p0. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol5.p1. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 Volume name & Plex : test-vol5.p2. Plex State : InUse
    DEBUG: 2019/07/11 16:56:47 All plexes of volume "test-vol5" are in "InUse" state.
    DEBUG: 2019/07/11 16:56:47 Running read fio job on all volumes: 
    DEBUG: 2019/07/11 16:56:48 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 16:56:48 Changing preferred plex of volume: test-vol3. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 16:56:48 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 0
    DEBUG: 2019/07/11 16:56:49 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 16:56:49 Changing preferred plex of volume: test-vol5. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 16:56:49 Changing preferred plex of volume: test-vol4. Volume load index: 1.New preferred plex: 0
    DEBUG: 2019/07/11 16:56:49 Running Verify IOs on node : bosserv9 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 16:56:50 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 16:56:50 Changing preferred plex of volume: test-vol7. Volume load index: 2.New preferred plex: 0
    DEBUG: 2019/07/11 16:56:51 Running Verify IOs on node : bosserv7 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 16:56:51 Running Verify IOs on node : bosserv8 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 16:57:51 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 16:57:52 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 16:57:52 Changing preferred plex of volume: test-vol3. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 16:57:52 Running Verify IOs on node : bosserv9 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 16:57:53 Changing preferred plex of volume: test-vol5. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 16:57:54 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 1
    DEBUG: 2019/07/11 16:57:54 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 16:57:55 Running Verify IOs on node : bosserv8 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 16:57:55 Changing preferred plex of volume: test-vol4. Volume load index: 1.New preferred plex: 1
    DEBUG: 2019/07/11 16:57:56 Changing preferred plex of volume: test-vol7. Volume load index: 2.New preferred plex: 1
    DEBUG: 2019/07/11 16:57:57 Running Verify IOs on node : bosserv7 and plex p1
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 16:59:34 Changing preferred plex of volume: test-vol1. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 16:59:34 Changing preferred plex of volume: test-vol3. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 16:59:35 Changing preferred plex of volume: test-vol4. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 16:59:36 Changing preferred plex of volume: test-vol5. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 16:59:36 Changing preferred plex of volume: test-vol2. Volume load index: 0.New preferred plex: 2
    DEBUG: 2019/07/11 16:59:36 Changing preferred plex of volume: test-vol7. Volume load index: 2.New preferred plex: 2
    DEBUG: 2019/07/11 16:59:37 Changing preferred plex of volume: test-vol8. Volume load index: 2.New preferred plex: 2
    DEBUG: 2019/07/11 16:59:37 Running Verify IOs on node : bosserv7 and plex p2
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 16:59:37 Changing preferred plex of volume: test-vol6. Volume load index: 1.New preferred plex: 2
    DEBUG: 2019/07/11 16:59:37 Running Verify IOs on node : bosserv8 and plex p2
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1 --name=dev3 --filename=/dev/nvme3n1
    DEBUG: 2019/07/11 16:59:38 Running Verify IOs on node : bosserv9 and plex p2
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme2n1
    DEBUG: 2019/07/11 17:01:23 Detach & delete all volumes: 
[AfterEach] Create simple volumes, do IOs, add plex. While the plex starts resyncing, add another plex. Validate data on each plex of each volume.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1982
    DEBUG: 2019/07/11 17:02:16 END_TEST Mirroring.OnlinePlexAddWhileOtherPlexIsResyncing Time-taken : 780.405795597

[32mâ€¢ [SLOW TEST:780.406 seconds][0m
Mirroring.OnlinePlexAddWhileOtherPlexIsResyncing Weekly SM_PlexAdd-1.2
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1965[0m
  Create simple volumes, do IOs, add plex. While the plex starts resyncing, add another plex. Validate data on each plex of each volume.
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1966[0m
    Create simple volumes, do IOs, add plex. While the plex starts resyncing, add another plex. Validate data on each plex of each volume.
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:1987[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.StressExhaustRemoteStorageCtrlsAndStorageCtrls Weekly RS_Stress-1.4 RS_Stress-1.5[0m [90mExhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.[0m 
  [1mExhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4196[0m
[BeforeEach] Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4181
    DEBUG: 2019/07/11 17:02:16 START_TEST RemoteStorage.StressExhaustRemoteStorageCtrlsAndStorageCtrls
    DEBUG: 2019/07/11 17:02:16 Login to cluster
    DEBUG: 2019/07/11 17:02:16 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 17:02:16 Checking basic Vnic usage
    DEBUG: 2019/07/11 17:02:17 Updating inventory struct
    DEBUG: 2019/07/11 17:02:23 Creating storage classes
[It] Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4196
    DEBUG: 2019/07/11 17:02:45 Create 64 single plex volumes per cluster node: 
    DEBUG: 2019/07/11 17:02:45 Creating volumes on the nodes : [bosserv7 bosserv8 bosserv9]
    DEBUG: 2019/07/11 17:03:39 Attaching volumes of node bosserv8 on node bosserv7:
    DEBUG: 2019/07/11 17:05:40 Attaching volumes of node bosserv9 on node bosserv8:
    DEBUG: 2019/07/11 17:07:39 Attaching volumes of node bosserv7 on node bosserv9:
    DEBUG: 2019/07/11 17:09:38 Attach remaining volumes locally: 
    DEBUG: 2019/07/11 17:15:30 Ensure all storage controllers & remote controllers are consumed: 
    DEBUG: 2019/07/11 17:15:30 Do write IOs on volumes attached to each cluster node: 
    DEBUG: 2019/07/11 17:15:31 Running Write IOs on node : bosserv8 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=write --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=300 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme33n1 --name=dev2 --filename=/dev/nvme34n1 --name=dev3 --filename=/dev/nvme35n1 --name=dev4 --filename=/dev/nvme36n1 --name=dev5 --filename=/dev/nvme37n1 --name=dev6 --filename=/dev/nvme38n1 --name=dev7 --filename=/dev/nvme39n1 --name=dev8 --filename=/dev/nvme40n1 --name=dev9 --filename=/dev/nvme41n1 --name=dev10 --filename=/dev/nvme42n1 --name=dev11 --filename=/dev/nvme43n1 --name=dev12 --filename=/dev/nvme44n1 --name=dev13 --filename=/dev/nvme45n1 --name=dev14 --filename=/dev/nvme46n1 --name=dev15 --filename=/dev/nvme47n1 --name=dev16 --filename=/dev/nvme48n1 --name=dev17 --filename=/dev/nvme49n1 --name=dev18 --filename=/dev/nvme50n1 --name=dev19 --filename=/dev/nvme51n1 --name=dev20 --filename=/dev/nvme52n1 --name=dev21 --filename=/dev/nvme53n1 --name=dev22 --filename=/dev/nvme54n1 --name=dev23 --filename=/dev/nvme55n1 --name=dev24 --filename=/dev/nvme56n1 --name=dev25 --filename=/dev/nvme57n1 --name=dev26 --filename=/dev/nvme58n1 --name=dev27 --filename=/dev/nvme59n1 --name=dev28 --filename=/dev/nvme60n1 --name=dev29 --filename=/dev/nvme61n1 --name=dev30 --filename=/dev/nvme62n1 --name=dev31 --filename=/dev/nvme63n1 --name=dev32 --filename=/dev/nvme64n1 --name=dev33 --filename=/dev/nvme1n1 --name=dev34 --filename=/dev/nvme10n1 --name=dev35 --filename=/dev/nvme11n1 --name=dev36 --filename=/dev/nvme12n1 --name=dev37 --filename=/dev/nvme13n1 --name=dev38 --filename=/dev/nvme14n1 --name=dev39 --filename=/dev/nvme15n1 --name=dev40 --filename=/dev/nvme16n1 --name=dev41 --filename=/dev/nvme17n1 --name=dev42 --filename=/dev/nvme18n1 --name=dev43 --filename=/dev/nvme19n1 --name=dev44 --filename=/dev/nvme2n1 --name=dev45 --filename=/dev/nvme20n1 --name=dev46 --filename=/dev/nvme21n1 --name=dev47 --filename=/dev/nvme22n1 --name=dev48 --filename=/dev/nvme23n1 --name=dev49 --filename=/dev/nvme24n1 --name=dev50 --filename=/dev/nvme25n1 --name=dev51 --filename=/dev/nvme26n1 --name=dev52 --filename=/dev/nvme27n1 --name=dev53 --filename=/dev/nvme28n1 --name=dev54 --filename=/dev/nvme29n1 --name=dev55 --filename=/dev/nvme3n1 --name=dev56 --filename=/dev/nvme30n1 --name=dev57 --filename=/dev/nvme31n1 --name=dev58 --filename=/dev/nvme32n1 --name=dev59 --filename=/dev/nvme4n1 --name=dev60 --filename=/dev/nvme5n1 --name=dev61 --filename=/dev/nvme6n1 --name=dev62 --filename=/dev/nvme7n1 --name=dev63 --filename=/dev/nvme8n1 --name=dev64 --filename=/dev/nvme9n1
    DEBUG: 2019/07/11 17:15:31 Running Write IOs on node : bosserv9 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=write --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=300 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme10n1 --name=dev3 --filename=/dev/nvme11n1 --name=dev4 --filename=/dev/nvme12n1 --name=dev5 --filename=/dev/nvme13n1 --name=dev6 --filename=/dev/nvme14n1 --name=dev7 --filename=/dev/nvme15n1 --name=dev8 --filename=/dev/nvme16n1 --name=dev9 --filename=/dev/nvme17n1 --name=dev10 --filename=/dev/nvme18n1 --name=dev11 --filename=/dev/nvme19n1 --name=dev12 --filename=/dev/nvme2n1 --name=dev13 --filename=/dev/nvme20n1 --name=dev14 --filename=/dev/nvme21n1 --name=dev15 --filename=/dev/nvme22n1 --name=dev16 --filename=/dev/nvme23n1 --name=dev17 --filename=/dev/nvme24n1 --name=dev18 --filename=/dev/nvme25n1 --name=dev19 --filename=/dev/nvme26n1 --name=dev20 --filename=/dev/nvme27n1 --name=dev21 --filename=/dev/nvme28n1 --name=dev22 --filename=/dev/nvme29n1 --name=dev23 --filename=/dev/nvme3n1 --name=dev24 --filename=/dev/nvme30n1 --name=dev25 --filename=/dev/nvme31n1 --name=dev26 --filename=/dev/nvme32n1 --name=dev27 --filename=/dev/nvme4n1 --name=dev28 --filename=/dev/nvme5n1 --name=dev29 --filename=/dev/nvme6n1 --name=dev30 --filename=/dev/nvme7n1 --name=dev31 --filename=/dev/nvme8n1 --name=dev32 --filename=/dev/nvme9n1 --name=dev33 --filename=/dev/nvme33n1 --name=dev34 --filename=/dev/nvme34n1 --name=dev35 --filename=/dev/nvme35n1 --name=dev36 --filename=/dev/nvme36n1 --name=dev37 --filename=/dev/nvme37n1 --name=dev38 --filename=/dev/nvme38n1 --name=dev39 --filename=/dev/nvme39n1 --name=dev40 --filename=/dev/nvme40n1 --name=dev41 --filename=/dev/nvme41n1 --name=dev42 --filename=/dev/nvme42n1 --name=dev43 --filename=/dev/nvme43n1 --name=dev44 --filename=/dev/nvme44n1 --name=dev45 --filename=/dev/nvme45n1 --name=dev46 --filename=/dev/nvme46n1 --name=dev47 --filename=/dev/nvme47n1 --name=dev48 --filename=/dev/nvme48n1 --name=dev49 --filename=/dev/nvme49n1 --name=dev50 --filename=/dev/nvme50n1 --name=dev51 --filename=/dev/nvme51n1 --name=dev52 --filename=/dev/nvme52n1 --name=dev53 --filename=/dev/nvme53n1 --name=dev54 --filename=/dev/nvme54n1 --name=dev55 --filename=/dev/nvme55n1 --name=dev56 --filename=/dev/nvme56n1 --name=dev57 --filename=/dev/nvme57n1 --name=dev58 --filename=/dev/nvme58n1 --name=dev59 --filename=/dev/nvme59n1 --name=dev60 --filename=/dev/nvme60n1 --name=dev61 --filename=/dev/nvme61n1 --name=dev62 --filename=/dev/nvme62n1 --name=dev63 --filename=/dev/nvme63n1 --name=dev64 --filename=/dev/nvme64n1
    DEBUG: 2019/07/11 17:15:31 Running Write IOs on node : bosserv7 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=write --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=300 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme33n1 --name=dev2 --filename=/dev/nvme34n1 --name=dev3 --filename=/dev/nvme35n1 --name=dev4 --filename=/dev/nvme36n1 --name=dev5 --filename=/dev/nvme37n1 --name=dev6 --filename=/dev/nvme38n1 --name=dev7 --filename=/dev/nvme39n1 --name=dev8 --filename=/dev/nvme40n1 --name=dev9 --filename=/dev/nvme41n1 --name=dev10 --filename=/dev/nvme42n1 --name=dev11 --filename=/dev/nvme43n1 --name=dev12 --filename=/dev/nvme44n1 --name=dev13 --filename=/dev/nvme45n1 --name=dev14 --filename=/dev/nvme46n1 --name=dev15 --filename=/dev/nvme47n1 --name=dev16 --filename=/dev/nvme48n1 --name=dev17 --filename=/dev/nvme49n1 --name=dev18 --filename=/dev/nvme50n1 --name=dev19 --filename=/dev/nvme51n1 --name=dev20 --filename=/dev/nvme52n1 --name=dev21 --filename=/dev/nvme53n1 --name=dev22 --filename=/dev/nvme54n1 --name=dev23 --filename=/dev/nvme55n1 --name=dev24 --filename=/dev/nvme56n1 --name=dev25 --filename=/dev/nvme57n1 --name=dev26 --filename=/dev/nvme58n1 --name=dev27 --filename=/dev/nvme59n1 --name=dev28 --filename=/dev/nvme60n1 --name=dev29 --filename=/dev/nvme61n1 --name=dev30 --filename=/dev/nvme62n1 --name=dev31 --filename=/dev/nvme63n1 --name=dev32 --filename=/dev/nvme64n1 --name=dev33 --filename=/dev/nvme1n1 --name=dev34 --filename=/dev/nvme10n1 --name=dev35 --filename=/dev/nvme11n1 --name=dev36 --filename=/dev/nvme12n1 --name=dev37 --filename=/dev/nvme13n1 --name=dev38 --filename=/dev/nvme14n1 --name=dev39 --filename=/dev/nvme15n1 --name=dev40 --filename=/dev/nvme16n1 --name=dev41 --filename=/dev/nvme17n1 --name=dev42 --filename=/dev/nvme18n1 --name=dev43 --filename=/dev/nvme19n1 --name=dev44 --filename=/dev/nvme2n1 --name=dev45 --filename=/dev/nvme20n1 --name=dev46 --filename=/dev/nvme21n1 --name=dev47 --filename=/dev/nvme22n1 --name=dev48 --filename=/dev/nvme23n1 --name=dev49 --filename=/dev/nvme24n1 --name=dev50 --filename=/dev/nvme25n1 --name=dev51 --filename=/dev/nvme26n1 --name=dev52 --filename=/dev/nvme27n1 --name=dev53 --filename=/dev/nvme28n1 --name=dev54 --filename=/dev/nvme29n1 --name=dev55 --filename=/dev/nvme3n1 --name=dev56 --filename=/dev/nvme30n1 --name=dev57 --filename=/dev/nvme31n1 --name=dev58 --filename=/dev/nvme32n1 --name=dev59 --filename=/dev/nvme4n1 --name=dev60 --filename=/dev/nvme5n1 --name=dev61 --filename=/dev/nvme6n1 --name=dev62 --filename=/dev/nvme7n1 --name=dev63 --filename=/dev/nvme8n1 --name=dev64 --filename=/dev/nvme9n1
    DEBUG: 2019/07/11 17:20:39 Read pattern written on volumes: 
    DEBUG: 2019/07/11 17:20:39 Running Verify IOs on node : bosserv9 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=read --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme10n1 --name=dev3 --filename=/dev/nvme11n1 --name=dev4 --filename=/dev/nvme12n1 --name=dev5 --filename=/dev/nvme13n1 --name=dev6 --filename=/dev/nvme14n1 --name=dev7 --filename=/dev/nvme15n1 --name=dev8 --filename=/dev/nvme16n1 --name=dev9 --filename=/dev/nvme17n1 --name=dev10 --filename=/dev/nvme18n1 --name=dev11 --filename=/dev/nvme19n1 --name=dev12 --filename=/dev/nvme2n1 --name=dev13 --filename=/dev/nvme20n1 --name=dev14 --filename=/dev/nvme21n1 --name=dev15 --filename=/dev/nvme22n1 --name=dev16 --filename=/dev/nvme23n1 --name=dev17 --filename=/dev/nvme24n1 --name=dev18 --filename=/dev/nvme25n1 --name=dev19 --filename=/dev/nvme26n1 --name=dev20 --filename=/dev/nvme27n1 --name=dev21 --filename=/dev/nvme28n1 --name=dev22 --filename=/dev/nvme29n1 --name=dev23 --filename=/dev/nvme3n1 --name=dev24 --filename=/dev/nvme30n1 --name=dev25 --filename=/dev/nvme31n1 --name=dev26 --filename=/dev/nvme32n1 --name=dev27 --filename=/dev/nvme4n1 --name=dev28 --filename=/dev/nvme5n1 --name=dev29 --filename=/dev/nvme6n1 --name=dev30 --filename=/dev/nvme7n1 --name=dev31 --filename=/dev/nvme8n1 --name=dev32 --filename=/dev/nvme9n1 --name=dev33 --filename=/dev/nvme33n1 --name=dev34 --filename=/dev/nvme34n1 --name=dev35 --filename=/dev/nvme35n1 --name=dev36 --filename=/dev/nvme36n1 --name=dev37 --filename=/dev/nvme37n1 --name=dev38 --filename=/dev/nvme38n1 --name=dev39 --filename=/dev/nvme39n1 --name=dev40 --filename=/dev/nvme40n1 --name=dev41 --filename=/dev/nvme41n1 --name=dev42 --filename=/dev/nvme42n1 --name=dev43 --filename=/dev/nvme43n1 --name=dev44 --filename=/dev/nvme44n1 --name=dev45 --filename=/dev/nvme45n1 --name=dev46 --filename=/dev/nvme46n1 --name=dev47 --filename=/dev/nvme47n1 --name=dev48 --filename=/dev/nvme48n1 --name=dev49 --filename=/dev/nvme49n1 --name=dev50 --filename=/dev/nvme50n1 --name=dev51 --filename=/dev/nvme51n1 --name=dev52 --filename=/dev/nvme52n1 --name=dev53 --filename=/dev/nvme53n1 --name=dev54 --filename=/dev/nvme54n1 --name=dev55 --filename=/dev/nvme55n1 --name=dev56 --filename=/dev/nvme56n1 --name=dev57 --filename=/dev/nvme57n1 --name=dev58 --filename=/dev/nvme58n1 --name=dev59 --filename=/dev/nvme59n1 --name=dev60 --filename=/dev/nvme60n1 --name=dev61 --filename=/dev/nvme61n1 --name=dev62 --filename=/dev/nvme62n1 --name=dev63 --filename=/dev/nvme63n1 --name=dev64 --filename=/dev/nvme64n1
    DEBUG: 2019/07/11 17:20:40 Running Verify IOs on node : bosserv8 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=read --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme33n1 --name=dev2 --filename=/dev/nvme34n1 --name=dev3 --filename=/dev/nvme35n1 --name=dev4 --filename=/dev/nvme36n1 --name=dev5 --filename=/dev/nvme37n1 --name=dev6 --filename=/dev/nvme38n1 --name=dev7 --filename=/dev/nvme39n1 --name=dev8 --filename=/dev/nvme40n1 --name=dev9 --filename=/dev/nvme41n1 --name=dev10 --filename=/dev/nvme42n1 --name=dev11 --filename=/dev/nvme43n1 --name=dev12 --filename=/dev/nvme44n1 --name=dev13 --filename=/dev/nvme45n1 --name=dev14 --filename=/dev/nvme46n1 --name=dev15 --filename=/dev/nvme47n1 --name=dev16 --filename=/dev/nvme48n1 --name=dev17 --filename=/dev/nvme49n1 --name=dev18 --filename=/dev/nvme50n1 --name=dev19 --filename=/dev/nvme51n1 --name=dev20 --filename=/dev/nvme52n1 --name=dev21 --filename=/dev/nvme53n1 --name=dev22 --filename=/dev/nvme54n1 --name=dev23 --filename=/dev/nvme55n1 --name=dev24 --filename=/dev/nvme56n1 --name=dev25 --filename=/dev/nvme57n1 --name=dev26 --filename=/dev/nvme58n1 --name=dev27 --filename=/dev/nvme59n1 --name=dev28 --filename=/dev/nvme60n1 --name=dev29 --filename=/dev/nvme61n1 --name=dev30 --filename=/dev/nvme62n1 --name=dev31 --filename=/dev/nvme63n1 --name=dev32 --filename=/dev/nvme64n1 --name=dev33 --filename=/dev/nvme1n1 --name=dev34 --filename=/dev/nvme10n1 --name=dev35 --filename=/dev/nvme11n1 --name=dev36 --filename=/dev/nvme12n1 --name=dev37 --filename=/dev/nvme13n1 --name=dev38 --filename=/dev/nvme14n1 --name=dev39 --filename=/dev/nvme15n1 --name=dev40 --filename=/dev/nvme16n1 --name=dev41 --filename=/dev/nvme17n1 --name=dev42 --filename=/dev/nvme18n1 --name=dev43 --filename=/dev/nvme19n1 --name=dev44 --filename=/dev/nvme2n1 --name=dev45 --filename=/dev/nvme20n1 --name=dev46 --filename=/dev/nvme21n1 --name=dev47 --filename=/dev/nvme22n1 --name=dev48 --filename=/dev/nvme23n1 --name=dev49 --filename=/dev/nvme24n1 --name=dev50 --filename=/dev/nvme25n1 --name=dev51 --filename=/dev/nvme26n1 --name=dev52 --filename=/dev/nvme27n1 --name=dev53 --filename=/dev/nvme28n1 --name=dev54 --filename=/dev/nvme29n1 --name=dev55 --filename=/dev/nvme3n1 --name=dev56 --filename=/dev/nvme30n1 --name=dev57 --filename=/dev/nvme31n1 --name=dev58 --filename=/dev/nvme32n1 --name=dev59 --filename=/dev/nvme4n1 --name=dev60 --filename=/dev/nvme5n1 --name=dev61 --filename=/dev/nvme6n1 --name=dev62 --filename=/dev/nvme7n1 --name=dev63 --filename=/dev/nvme8n1 --name=dev64 --filename=/dev/nvme9n1
    DEBUG: 2019/07/11 17:20:40 Running Verify IOs on node : bosserv7 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=read --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme33n1 --name=dev2 --filename=/dev/nvme34n1 --name=dev3 --filename=/dev/nvme35n1 --name=dev4 --filename=/dev/nvme36n1 --name=dev5 --filename=/dev/nvme37n1 --name=dev6 --filename=/dev/nvme38n1 --name=dev7 --filename=/dev/nvme39n1 --name=dev8 --filename=/dev/nvme40n1 --name=dev9 --filename=/dev/nvme41n1 --name=dev10 --filename=/dev/nvme42n1 --name=dev11 --filename=/dev/nvme43n1 --name=dev12 --filename=/dev/nvme44n1 --name=dev13 --filename=/dev/nvme45n1 --name=dev14 --filename=/dev/nvme46n1 --name=dev15 --filename=/dev/nvme47n1 --name=dev16 --filename=/dev/nvme48n1 --name=dev17 --filename=/dev/nvme49n1 --name=dev18 --filename=/dev/nvme50n1 --name=dev19 --filename=/dev/nvme51n1 --name=dev20 --filename=/dev/nvme52n1 --name=dev21 --filename=/dev/nvme53n1 --name=dev22 --filename=/dev/nvme54n1 --name=dev23 --filename=/dev/nvme55n1 --name=dev24 --filename=/dev/nvme56n1 --name=dev25 --filename=/dev/nvme57n1 --name=dev26 --filename=/dev/nvme58n1 --name=dev27 --filename=/dev/nvme59n1 --name=dev28 --filename=/dev/nvme60n1 --name=dev29 --filename=/dev/nvme61n1 --name=dev30 --filename=/dev/nvme62n1 --name=dev31 --filename=/dev/nvme63n1 --name=dev32 --filename=/dev/nvme64n1 --name=dev33 --filename=/dev/nvme1n1 --name=dev34 --filename=/dev/nvme10n1 --name=dev35 --filename=/dev/nvme11n1 --name=dev36 --filename=/dev/nvme12n1 --name=dev37 --filename=/dev/nvme13n1 --name=dev38 --filename=/dev/nvme14n1 --name=dev39 --filename=/dev/nvme15n1 --name=dev40 --filename=/dev/nvme16n1 --name=dev41 --filename=/dev/nvme17n1 --name=dev42 --filename=/dev/nvme18n1 --name=dev43 --filename=/dev/nvme19n1 --name=dev44 --filename=/dev/nvme2n1 --name=dev45 --filename=/dev/nvme20n1 --name=dev46 --filename=/dev/nvme21n1 --name=dev47 --filename=/dev/nvme22n1 --name=dev48 --filename=/dev/nvme23n1 --name=dev49 --filename=/dev/nvme24n1 --name=dev50 --filename=/dev/nvme25n1 --name=dev51 --filename=/dev/nvme26n1 --name=dev52 --filename=/dev/nvme27n1 --name=dev53 --filename=/dev/nvme28n1 --name=dev54 --filename=/dev/nvme29n1 --name=dev55 --filename=/dev/nvme3n1 --name=dev56 --filename=/dev/nvme30n1 --name=dev57 --filename=/dev/nvme31n1 --name=dev58 --filename=/dev/nvme32n1 --name=dev59 --filename=/dev/nvme4n1 --name=dev60 --filename=/dev/nvme5n1 --name=dev61 --filename=/dev/nvme6n1 --name=dev62 --filename=/dev/nvme7n1 --name=dev63 --filename=/dev/nvme8n1 --name=dev64 --filename=/dev/nvme9n1
    DEBUG: 2019/07/11 17:25:18 Detach volumes:
    DEBUG: 2019/07/11 17:25:18 Detaching volumes on the node : bosserv7
    DEBUG: 2019/07/11 17:25:18 Detaching volumes on the node : bosserv9
    DEBUG: 2019/07/11 17:25:18 Detaching volumes on the node : bosserv8
    DEBUG: 2019/07/11 17:25:47 Delete volumes: 
[AfterEach] Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4191
    DEBUG: 2019/07/11 17:27:09 END_TEST RemoteStorage.StressExhaustRemoteStorageCtrlsAndStorageCtrls Time-taken : 1493.812438786

[32mâ€¢ [SLOW TEST:1493.813 seconds][0m
RemoteStorage.StressExhaustRemoteStorageCtrlsAndStorageCtrls Weekly RS_Stress-1.4 RS_Stress-1.5
[90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4168[0m
  Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
  [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4170[0m
    Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
    [90m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/volume.go:4196[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0mMirroring.RebootDestinationNodeDuringResync Weekly SM_Reboot-2.14[0m [90mreboot the destination node while resync is in progress and verify data is consistent across all plexes after reboot[0m 
  [1mreboot the destination node while resync is in progress and verify data is consistent across all plexes after reboot[0m
  [37m/dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:752[0m
[BeforeEach] reboot the destination node while resync is in progress and verify data is consistent across all plexes after reboot
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:738
    DEBUG: 2019/07/11 17:27:09 START_TEST Mirroring.RebootDestinationNodeDuringResync
    DEBUG: 2019/07/11 17:27:09 Login to cluster
    DEBUG: 2019/07/11 17:27:09 Login commands is :  -s 172.16.230.103 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2019/07/11 17:27:10 Checking basic Vnic usage
    DEBUG: 2019/07/11 17:27:10 Updating inventory struct
    DEBUG: 2019/07/11 17:27:17 Creating storage classes
[It] reboot the destination node while resync is in progress and verify data is consistent across all plexes after reboot
  /dwshome/yogesh/workspace/GA-2.2.0/.go/src/dws/test/e2e/tests/mirroring.go:752
    DEBUG: 2019/07/11 17:27:38 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2019/07/11 17:27:44 FBM and L1 usage is Zero across all nodes

    DEBUG: 2019/07/11 17:27:44 Assigning label to nodes where the plexes of mirrored volumes should get scheduled
    DEBUG: 2019/07/11 17:27:44 Assigned label : mirror=true to node : bosserv8
    DEBUG: 2019/07/11 17:27:44 Assigned label : mirror=true to node : bosserv7
    DEBUG: 2019/07/11 17:27:44 Assigned label : mirror=true to node : bosserv9
    DEBUG: 2019/07/11 17:27:44 Creating 8 volumes of random sizes
    DEBUG: 2019/07/11 17:27:44 Mirror Count: 3
    DEBUG: 2019/07/11 17:27:53 Attaching all 8 volumes to node bosserv7
    DEBUG: 2019/07/11 17:28:24 Initiator node : bosserv7
    DEBUG: 2019/07/11 17:28:24 Nodes to reboot : bosserv8 bosserv9
    DEBUG: 2019/07/11 17:28:24 Node to reboot during Resync : bosserv8
    DEBUG: 2019/07/11 17:28:27 Running WRITE fio job on: bosserv7. FIO Command : echo -e '#!/bin/bash\n\nsudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096 --runtime=400 --blocksize=4K --iodepth=32  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 > /tmp/fio_result.txt & > /dev/null 2>&1' > /tmp/fio_run.sh

    DEBUG: 2019/07/11 17:28:30 Number of running fio process: 11

    DEBUG: 2019/07/11 17:31:51 Getting cluster quorum nodes
    DEBUG: 2019/07/11 17:31:51 Powering OFF the node bosserv8
    DEBUG: 2019/07/11 17:31:56 Node 172.16.230.16 took 5 seconds to power off
    DEBUG: 2019/07/11 17:31:56 Powering OFF the node bosserv9
    DEBUG: 2019/07/11 17:32:01 Node 172.16.230.18 took 5 seconds to power off
    DEBUG: 2019/07/11 17:32:01 Ensuring that bosserv8 node is unreachable: 
    DEBUG: 2019/07/11 17:32:01 Executing ping command: ping  -c 5 -W 5 bosserv8
    DEBUG: 2019/07/11 17:32:08 Ensuring that bosserv9 node is unreachable: 
    DEBUG: 2019/07/11 17:32:08 Executing ping command: ping  -c 5 -W 5 bosserv9
    DEBUG: 2019/07/11 17:32:17 Getting cluster quorum nodes
    DEBUG: 2019/07/11 17:32:32 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:32:47 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:33:02 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:33:17 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:33:32 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:33:48 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:34:03 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:34:18 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:34:48 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:34:49 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:34:52 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:34:55 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:34:58 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:34:59 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:35:02 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:35:05 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:35:08 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:35:11 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:35:14 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:35:17 Error: . Retrying once again...
    DEBUG: 2019/07/11 17:35:20 Error: . Retrying once again...
    ERROR: 2019/07/11 17:35:20  util.go:212: TestFailed Failed to get cluster status in 36 attempts.
    DEBUG: 2019/07/11 17:35:20 Collecting dw-techsupport log from all test nodes

    DEBUG: 2019/07/11 17:35:20 
Getting techsupport logs for all nodes
    DEBUG: 2019/07/11 17:35:20 Create techsupport log directory : 2019-07-11T17-35-20
    DEBUG: 2019/07/11 17:35:22 Cluster info save failed with err: failed to run commmand 'sudo dctl -o json -s 172.16.230.103 cluster info --save -y', output:Get https://172.16.230.103:443/api/v1/clusterdiscover: dial tcp 172.16.230.103:443: connect: no route to host
Cannot reach cluster, please check if vip / fqdn is reachable
, error:

    DEBUG: 2019/07/11 17:35:23 Failed to dial: dial tcp 172.16.230.16:22: connect: no route to host 
    DEBUG: 2019/07/11 17:35:23 Cluster info save failed with err: failed to run commmand 'sudo dctl -o json -s 172.16.230.103 cluster info --save -y', output:, error:

    DEBUG: 2019/07/11 17:35:26 Failed to dial: dial tcp 172.16.230.16:22: connect: no route to host 
    DEBUG: 2019/07/11 17:35:26 Cluster login failed with err: failed to run commmand 'sudo dctl -o json login -u admin -p Diamanti@111', output:, error:

    DEBUG: 2019/07/11 17:35:29 Failed to dial: dial tcp 172.16.230.16:22: connect: no route to host 
    DEBUG: 2019/07/11 17:35:29 Getting tech support for 172.16.230.16 node, to directory 2019-07-11T17-35-20

    ERROR: 2019/07/11 17:35:32  util.go:1582: Could not get tech support file for node 172.16.230.16, Error: exit status 1
    DEBUG: 2019/07/11 17:35:38 Failed to dial: dial tcp 172.16.230.18:22: connect: no route to host 
    DEBUG: 2019/07/11 17:35:38 Cluster info save failed with err: failed to run commmand 'sudo dctl -o json -s 172.16.230.103 cluster info --save -y', output:, error:

    DEBUG: 2019/07/11 17:35:41 Failed to dial: dial tcp 172.16.230.18:22: connect: no route to host 
    DEBUG: 2019/07/11 17:35:41 Cluster login failed with err: failed to run commmand 'sudo dctl -o json login -u admin -p Diamanti@111', output:, error:

    DEBUG: 2019/07/11 17:35:44 Failed to dial: dial tcp 172.16.230.18:22: connect: no route to host 
    DEBUG: 2019/07/11 17:35:44 Getting tech support for 172.16.230.18 node, to directory 2019-07-11T17-35-20

    ERROR: 2019/07/11 17:35:47  util.go:1582: Could not get tech support file for node 172.16.230.18, Error: exit status 1
    DEBUG: 2019/07/11 17:41:35 Getting tech support for 172.16.230.14 node, to directory 2019-07-11T17-35-20

    DEBUG: 2019/07/11 17:41:36 Creating pod log directory : pod_description_and_logs
    DEBUG: 2019/07/11 17:41:36 Collecting pod description and logs for all the pods ...
    DEBUG: 2019/07/11 17:42:06 Collected techsupport log location : /home/rajat/2019-07-11T17-35-20
    DEBUG: 2019/07/11 17:42:06 Copying e2e log file to directory : /home/rajat/2019-07-11T17-35-20
    DEBUG: 2019/07/11 17:42:06 Changing permissions of directory, so that all users can write to : 2019-07-11T17-35-20
[91mTestcase failed, refreshing testbed...[0m    DEBUG: 2019/07/11 17:42:06 Destroying the cluster
    DEBUG: 2019/07/11 17:44:10 Error getting cluster info
%!(EXTRA string=failed to run commmand 'dctl -s 172.16.230.14  -o json cluster info', output:, error:Get https://172.16.230.14:443/api/v1/clusterdiscover: net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Timeout while performing the requested operation

)
    ERROR: 2019/07/11 17:44:10  util.go:1465: failed to run commmand 'dctl -s 172.16.230.14  -o json cluster info', output:, error:Get https://172.16.230.14:443/api/v1/clusterdiscover: net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Timeout while performing the requested operation



    ERROR: 2019/07/11 17:44:10  util.go:1466: [Could not destroy cluster before running tests : failed to run commmand 'dctl -s 172.16.230.14  -o json cluster info', output:, error:Get https://172.16.230.14:443/api/v1/clusterdiscover: net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Timeout while performing the requested operation

]

